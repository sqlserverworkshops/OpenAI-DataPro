{"cells":[{"cell_type":"markdown","metadata":{},"source":["![](../graphics/microsoftlogo.png)\n","\n","# Workshop: Unlocking AI Potential for the Data Professional - Azure OpenAI\n","\n","#### <i>A Microsoft Course from Microsoft Engineering and the FastTrack Team</i>\n","\n","<p style=\"border-bottom: 1px solid lightgrey;\"></p>\n","\n","<img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://raw.githubusercontent.com/microsoft/sqlworkshops/master/graphics/textbubble.png\"> <h2>Course Notebook: Module 1</h2>\n","\n","Welcome to this Microsoft solutions workshop on [*Unlocking AI Potential for the Data Professional with Azure OpenAI*](https://github.com/sqlserverworkshops/OpenAI-DataPro/tree/main). In this Notebook, you'll apply the concepts you learned in this Module.\n","\n","This Notebook contains recipes for some common applications of Artifiical Intelligence, Machine Learning, Deep Learning, Natural Language Processing, and Generative AI. \n","\n","You'll need a working knowledge of [pandas](http://pandas.pydata.org/), [matplotlib](http://matplotlib.org/), [numpy](http://www.numpy.org/), and, of course, [scikit-learn](http://scikit-learn.org/stable/) to benefit from it."]},{"cell_type":"code","execution_count":4,"metadata":{"collapsed":false,"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras\n","  Downloading keras-3.0.5-py3-none-any.whl.metadata (4.8 kB)\n","Collecting absl-py (from keras)\n","  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.10/site-packages (from keras) (1.26.4)\n","Collecting rich (from keras)\n","  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n","Collecting namex (from keras)\n","  Downloading namex-0.0.7-py3-none-any.whl.metadata (246 bytes)\n","Collecting h5py (from keras)\n","  Downloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n","Collecting dm-tree (from keras)\n","  Downloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\n","Collecting ml-dtypes (from keras)\n","  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting markdown-it-py>=2.2.0 (from rich->keras)\n","  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.10/site-packages (from rich->keras) (2.17.2)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n","  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dm_tree-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h5py-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n","\u001b[?25hDownloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n","Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Installing collected packages: namex, dm-tree, ml-dtypes, mdurl, h5py, absl-py, markdown-it-py, rich, keras\n","Successfully installed absl-py-2.1.0 dm-tree-0.1.8 h5py-3.10.0 keras-3.0.5 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.3.2 namex-0.0.7 rich-13.7.1\n"]}],"source":["# Notebook requirements\n","%matplotlib inline\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Artificial Intelligence: Simple \"Expert System\"\n","\n","The Following Python code shows a simple example of a \"Good Old Fashioned AI\" (GOFAI) program in Python. This program uses a basic rule-based system to diagnose a simple medical condition based on symptoms.\n","\n","This code creates a rule-based system for diagnosing a medical condition based on a set of symptoms. The `RuleBasedSystem` class has a dictionary of rules, where each key is a set of symptoms and each value is a possible diagnosis. The `diagnose` method takes a set of symptoms as input and returns a diagnosis based on the rules.\n","\n","Please note that this is a very simplified example and not an example of modern real-world AI systems, especially those used in healthcare, which are much more complex and sophisticated. \n","\n","**Always consult with a healthcare professional for medical advice**"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Diagnosis: You may have the flu.\n"]}],"source":["class RuleBasedSystem:\n","    def __init__(self):\n","        self.rules = {\n","            'fever': 'You may have a common cold.',\n","            'cough': 'You may have a common cold.',\n","            'fever and cough': 'You may have the flu.',\n","            'rash': 'You may have an allergic reaction.',\n","            'headache': 'You may be dehydrated.',\n","        }\n","\n","    def diagnose(self, symptoms):\n","        diagnosis = self.rules.get(symptoms, 'Symptoms not recognized.')\n","        return diagnosis\n","\n","# Create a rule-based system\n","system = RuleBasedSystem()\n","\n","# Diagnose based on symptoms\n","symptoms = 'fever and cough'\n","diagnosis = system.diagnose(symptoms)\n","\n","print(f'Diagnosis: {diagnosis}')"]},{"cell_type":"markdown","metadata":{},"source":["### Artificial Intelligence: Descision Tree using simple Bayesian Decision Theory\n","This is an over-simpified example of normative Bayesian decision theory in Python. This program uses Bayesian inference to update the probability estimate for a hypothesis as more evidence or information becomes available.\n","\n","This code creates a Bayesian decision system that updates its belief about the mean of a normal distribution given some observed data. The `BayesianDecision` class has a method `update` that takes a data array as input and updates the prior mean and standard deviation based on the data. The updated mean and standard deviation are then printed out.\n","\n","*Please note that this is a very simplified example and real-world AI systems, especially those used in decision making, are much more complex and sophisticated. Always consult with a professional for decision making advice*"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Posterior Mean: 0.7459543266315918\n","Posterior Standard Deviation: 0.4472135954999579\n"]}],"source":["import numpy as np\n","from scipy.stats import norm\n","\n","class BayesianDecision:\n","    def __init__(self, prior_mean, prior_std, likelihood_std):\n","        self.prior_mean = prior_mean\n","        self.prior_std = prior_std\n","        self.likelihood_std = likelihood_std\n","\n","    def update(self, data):\n","        # Calculate the posterior mean and standard deviation\n","        likelihood_variance = self.likelihood_std ** 2\n","        prior_variance = self.prior_std ** 2\n","        posterior_variance = 1 / ((1 / likelihood_variance) + (1 / prior_variance))\n","        posterior_mean = posterior_variance * ((self.prior_mean / prior_variance) + (np.mean(data) / likelihood_variance))\n","        self.prior_mean = posterior_mean\n","        self.prior_std = np.sqrt(posterior_variance)\n","        return self.prior_mean, self.prior_std\n","\n","# Initialize a Bayesian decision system\n","system = BayesianDecision(prior_mean=0, prior_std=1, likelihood_std=0.5)\n","\n","# Update the system with some data\n","data = np.random.normal(loc=1, scale=0.5, size=100)\n","posterior_mean, posterior_std = system.update(data)\n","\n","print(f'Posterior Mean: {posterior_mean}')\n","print(f'Posterior Standard Deviation: {posterior_std}')"]},{"cell_type":"markdown","metadata":{},"source":["### Machine Learning: Predicting results from data\n","\n","The following Python Code shows a simple example of a machine learning program using the `scikit-learn` library in Python. This program uses the `Iris` dataset to train a logistic regression model and make predictions.\n","\n","This code first loads the Iris dataset, which is a multivariate dataset introduced by the British statistician and biologist Ronald Fisher. It's often used as a beginner's dataset for machine learning and data visualization.\n","\n","The data is then split into a training set and a test set. The features are standardized to have a mean of 0 and a standard deviation of 1, which is a common requirement for many machine learning algorithms.\n","\n","A `logistic regression` model is trained on the training data, and then it makes predictions on the unseen test data. The predictions are then printed out."]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions: [1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n"]}],"source":["from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.linear_model import LogisticRegression\n","\n","# Load Iris dataset\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize the features\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","# Train a Logistic Regression model\n","model = LogisticRegression(random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","predictions = model.predict(X_test)\n","\n","print(f'Predictions: {predictions}')"]},{"cell_type":"markdown","metadata":{},"source":["This code is a simple example of a deep learning model using Python and Keras in a Jupyter notebook. This example will be a basic feedforward neural network for the MNIST dataset, which is a dataset of handwritten digits.\n","\n","This script first loads the MNIST dataset and reshapes it for use in the neural network. The pixel values are normalized and the labels are one-hot encoded. A simple feedforward neural network is defined, with a single hidden layer that has the same number of neurons as there are inputs (784). A rectifier activation function is used for the neurons in the hidden layer.\n","\n","A softmax activation function is used on the output layer to turn the outputs into probability-like values and allow one class of the 10 to be selected as the model's output prediction. Logarithmic loss is used as the loss function (called categorical_crossentropy in Keras) and the efficient ADAM gradient descent algorithm is used to learn the weights.\n","\n","The model is fit over 10 epochs with updates every 200 images. The test data is used as the validation dataset, allowing you to see the skill of the model as it trains. A verbose value of 2 is used to reduce the output to one line for each training epoch. Finally, the test dataset is used to evaluate the model and a classification error rate is printed.\n","\n","https://keras.io/guides/training_with_built_in_methods/ \n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torch in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (2.2.1)\n","Requirement already satisfied: filelock in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (2024.2.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n","Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["2024-03-01 14:10:47.158586: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-01 14:10:47.158768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-01 14:10:47.477081: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-03-01 14:10:48.136827: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-03-01 14:10:51.786676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"ename":"ImportError","evalue":"cannot import name 'ops' from 'keras' (/workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages/keras/__init__.py)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'ops' from 'keras' (/workspaces/OpenAI-DataPro/.venv/lib/python3.10/site-packages/keras/__init__.py)"]}],"source":["%pip install torch \n","#%pip install tensorflow\n","# We import torch & TF so as to use torch Dataloaders & tf.data.Datasets.\n","import torch\n","import tensorflow as tf\n","\n","import os\n","import numpy as np\n","import keras\n","from keras import layers\n","from keras import ops"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
