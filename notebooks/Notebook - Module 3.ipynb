{"cells":[{"cell_type":"markdown","metadata":{},"source":["![](../graphics/microsoftlogo.png)\n","\n","# Workshop: Unlocking AI Potential for the Data Professional - Azure OpenAI\n","\n","#### <i>A Microsoft Course from Microsoft Engineering and the FastTrack Team</i>\n","\n","<p style=\"border-bottom: 1px solid lightgrey;\"></p>\n","\n","<img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://raw.githubusercontent.com/microsoft/sqlworkshops/master/graphics/textbubble.png\"> <h2>Course Notebook: Module 3</h2>\n","\n","Welcome to this Microsoft solutions workshop on [*Unlocking AI Potential for the Data Professional with Azure OpenAI*](https://github.com/sqlserverworkshops/OpenAI-DataPro/tree/main). In this Notebook, you'll apply the concepts you learned in this Module.\n","\n","\n","Mastering the fundamentals and core concepts of OpenAI is indispensable for unlocking its full potential within Azure. Developers need a solid grasp of deploying Azure services like Azure OpenAI and Azure Cognitive Search, ensuring secure deployment aligned with responsible AI practices. This foundational knowledge guarantees that applications built on these services are not only functional but also ethically sound.\n","\n","Moreover, proficiency in interacting with OpenAI's Large Language Models (LLMs) via REST API is crucial for seamless integration into diverse applications. Developers must understand the underlying principles of OpenAI, including selecting the right model for specific tasks and discerning the advantages of different models in terms of token utilization and response precision. Understanding prompts, completions, chats and overall prompt engineering best practices is pivotal for crafting top-notch interactions with Azure OpenAI, whether it involves generating summaries, translations, or other functions.\n","\n","Furthermore, advanced concepts like smart load balancing for OpenAI endpoints and fine-tuning models are essential for maximizing performance and ensuring application resilience. As AI applications become increasingly intricate, grasping these core concepts not only empowers developers to construct more efficient solutions but also aids in mitigating potential risks associated with sophisticated language models. By simplifying the understanding of how these core concepts interconnect, our goal is to enable developers to build smarter applications using Azure OpenAI."]},{"cell_type":"markdown","metadata":{},"source":["# 3.2 Create Azure OpenAI Environment\n","\n","## Azure \n","\n","This notebook contains the script to create the necessary Azure environment to run the provided samples. The notebook uses [PowerShell](https://learn.microsoft.com/powershell/scripting/install/installing-powershell?view=powershell-7.3) and [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) to deploy all necessary Azure resources. Both tools are available on Windows, macOS and Linux environments.\n","\n","## Configuration\n","\n","This section performs two tasks:\n","\n","- Deployment of necessary Azure Services (Azure OpenAI, Azure Cognitive Search) to run samples\n","- Store all necessary service endpoints, service API keys, Azure OpenAI deployment names in a centralized file (../01_DemoEnvironment/conf/application.env). This file is used by all notebooks in this repo to connect and authenticate against the deployed Azure services.\n","\n","If you already have instances of Azure OpenAI and Azure Cognitive Search running you can rename the [configuration template](../conf/.env-sample) to `.env` and provide endpoint, API key and deployment names of a chat completion and an embedding model. We suggest to run the notebook to start a clean environment.\n","\n","### Visual Studio Code\n","\n","If you are running these steps below in Visual Studio Code make sure you switch your kernal to .NET Interactive so that it will run the PowerShell"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1:   Login to Azure; Get, Set subscription"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"metadata":{},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Check if you are already logged in\n","$loggedIn = az account show --query \"name\" -o tsv\n","\n","if ($null -ne $loggedIn) {\n","    Write-Host \"Already logged in as $loggedIn\"\n","} else {\n","    Write-Host \"Logging in...\"\n","    az login\n","}\n","# Retrieve default subscription id\n","$subscriptionId = (\n","    (\n","        az account list -o json `\n","            --query \"[?isDefault]\"\n","    ) | ConvertFrom-Json\n",").id\n","\n","# Set Subscription\n","az account set --subscription $subscriptionId\n","Write-Host \"Subscription set to $subscriptionId\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","If you're already logged in:\n","```\n","    Already logged in as xxxxx\n","    Subscription set to xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n","```\n","If you aren't logged in a browser window will pop-up which allows you to log in\n","```\n","    Logging in...\n","    Subscription set to xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2:   Define project unifier\n","\n","The project unifier is used to allow multiple deployments of services which have a need for a unique custom endpoint."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$random = Get-Random -Minimum 100 -Maximum 999\n","\n","Write-Host \"Unifier set to: $random\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Unifier set to: xxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3:   Create Resource Group\n","\n","In this sample all resources are deployed to `westus`. Feel free to change to your preferred location."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$resourceGroup = \"OpenAI-DataPro-RG\"\n","$location = \"westus\"\n","\n","az group create `\n","    --location $location `\n","    --resource-group $resourceGroup"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created resource group`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4:   Create Azure OpenAI instance\n","\n","An instance of Azure Cognitive Service with the kind `OpenAI` will be created. The `endpoint` and `API key` of the newly created instance are retrieved for later storage in the `application.env` file."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$csOpenAIName = \"aiservices$random\"\n","\n","az cognitiveservices account create `\n","    --name $csOpenAIName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --kind OpenAI `\n","    --sku S0 `\n","    --yes\n","\n","$csOpenAIEndpoint = ( `\n","    az cognitiveservices account show `\n","        --name $csOpenAIName `\n","        --resource-group $resourceGroup `\n","        --query properties.endpoint `\n","        --output tsv `\n",")\n","\n","$csOpenAIApiKey = (\n","    az cognitiveservices account keys list `\n","        --name $csOpenAIName `\n","        --resource-group $resourceGroup `\n","        --query key1 `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created Azure OpenAI instance`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5:   Deploy Azure OpenAI models\n","\n","Two LLM models are deployed to the newly created Azure Cognitive Service instance: \n","\n","- A chat completion model. In the sample we're deploying `gpt-35-turbo`. This can be replaced with other models providing a chat completion interface like `gpt-4`.\n","- A text embedding model. In the sample we're deploying `text-embedding-ada-002`. Any other text embedding model can be deployed as well."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Chat Completion Model GPT-3.5-turbo\n","$AOAI_GPT35_DEPLOYMENT = \"gpt-35-turbo\"\n","$modelName = \"gpt-35-turbo\"\n","$modelVersion = \"1106\"\n","$modelFormat = \"OpenAI\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT35_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Chat Completion Model GPT-4\n","$AOAI_GPT4_DEPLOYMENT = \"gpt-4\"\n","$modelName = \"gpt-4\"\n","$modelVersion = \"1106-Preview\"\n","$modelFormat = \"OpenAI\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT4_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Text Embedding Model\n","$AOAI_EMBEDDING_DEPLOYMENT = \"text-embedding-ada-002\"\n","$modelName = \"text-embedding-ada-002\"\n","$modelVersion = \"2\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_EMBEDDING_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# GPT-4 Vision Model - GPT-4 Turbo with Vision is the version of GPT-4 that accepts image inputs. It is available as the vision-preview model of gpt-4. The vision-preview model is available in only certain regions. For more information, see\n","# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#standard-deployment-model-availability\n","$AOAI_GPT4VISION_DEPLOYMENT = \"gpt-4-vision\"\n","$modelName = \"gpt-4\"\n","$modelVersion = \"vision-preview\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT4VISION_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly deployed models`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 6:   Create Azure Cognitive Search\n","\n","Azure Cognitive Search is deployed to use its [vector DB functionalities](https://learn.microsoft.com/en-us/azure/search/vector-search-overview). Just like with Azure OpenAI Cognitive Service, the `endpoint` and `API key` of the newly created instance are retrieved for later storage in the `application.env` file."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$csSearchName = \"aisearch$random\"\n","$csSearchSku = \"standard\"\n","\n","az search service create `\n","    --name $csSearchName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --sku $csSearchSku\n","\n","$csSearchEndpoint = \"https://$csSearchName.search.windows.net\"\n","\n","$csSearchApiKey = ( `\n","    az search admin-key show `\n","        --resource-group $resourceGroup `\n","        --service-name $csSearchName `\n","        --query primaryKey `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created cognitive search resource`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 7:   Create Azure Storage account\n","\n","Azure Storage is deployed to store data that can be used to generate indexes in Azure Cognitive Search."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$stgName = \"aistg$random\"\n","$stgSku = \"Standard_LRS\"\n","\n","az storage account create `\n","    --name $stgName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --sku $stgSku `\n","    --kind StorageV2 `\n","    --https-only true `\n","    --access-tier Hot\n","\n","$stgConnectionString = ( `\n","    az storage account show-connection-string `\n","        --name $stgName `\n","        --resource-group $resourceGroup `\n","        --query connectionString `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n","`JSON string describing the newly created storage account`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 8: Set environment variables & create application.env file"]},{"cell_type":"code","execution_count":13,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Environment variables set!\n","Configuration file created at: ../.env\n"]}],"source":["# Set environment variables\n","\n","$ENV:AOAI_ENDPOINT = $csOpenAIEndpoint\n","$ENV:AOAI_APIKEY = $csOpenAIApiKey\n","\n","#Azure Open AI GPT 3.5\n","$ENV:AOAI_GPT35_DEPLOYMENT = $AOAI_GPT35_DEPLOYMENT\n","\n","#Azure Open AI Embedding - text-embedding-ada-002\n","$ENV:AOAI_EMBEDDING_DEPLOYMENT = $AOAI_EMBEDDING_DEPLOYMENT\n","\n","#Azure Open AI GPT 4\n","$ENV:AOAI_GPT4_DEPLOYMENT = $AOAI_GPT4_DEPLOYMENT\n","\n","#Azure Open AI GPT 4 Vision\n","$ENV:AOAI_VISION_ENDPOINT = $csOpenAIEndpoint\n","$ENV:AOAI_VISION_APIKEY = $csOpenAIApiKey\n","$ENV:AOAI_GPT4VISION_DEPLOYMENT = $AOAI_GPT4VISION_DEPLOYMENT\n","\n","# Azure Search\n","$ENV:SEARCH_ENDPOINT = \"https://$csSearchEndpoint/\"\n","$ENV:SEARCH_APIKEY = $csSearchApiKey\n","\n","$ENV:STORAGE_CONNECTIONSTRING = $stgConnectionString\n","$ENV:ASSET_FOLDER = \"../../../../assets\"\n","\n","Write-Host \"Environment variables set!\"\n","\n","$configurationFile = \"../.env\"\n","\n","function Set-ConfigurationFileVariable($configurationFile, $variableName, $variableValue) {\n","    if (Select-String -Path $configurationFile -Pattern $variableName) {\n","        (Get-Content $configurationFile) | Foreach-Object {\n","            $_ -replace \"$variableName = .*\", \"$variableName=$variableValue\"\n","        } | Set-Content $configurationFile\n","    } else {\n","        Add-Content -Path $configurationFile -value \"$variableName=$variableValue\"\n","    }\n","}\n","\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_ENDPOINT\" $csOpenAIEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_APIKEY\" $csOpenAIApiKey\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT35_DEPLOYMENT\" $AOAI_GPT35_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_EMBEDDING_DEPLOYMENT\" $AOAI_EMBEDDING_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT4_DEPLOYMENT\" $AOAI_GPT4_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_VISION_ENDPOINT\" $csOpenAIEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_VISION_APIKEY\" $csOpenAIApiKey\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT4VISION_DEPLOYMENT\" $AOAI_GPT4VISION_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"SEARCH_ENDPOINT\" $csSearchEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"SEARCH_APIKEY\" $csSearchApiKey\n","Set-ConfigurationFileVariable $configurationFile \"STORAGE_CONNECTIONSTRING\" $stgConnectionString\n","Set-ConfigurationFileVariable $configurationFile \"ASSET_FOLDER\" \"../../../../assets\"\n","\n","\n","Write-Host \"Configuration file created at: $configurationFile\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Environment variables set!\n","Configuration file created at: xxxxxxxxxxxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 3.3 Basic Chat\n","\n","In this notebook, we'll explore basic prompt engineering techniques and recommendations that will help us elicit responses from Azure OpenAI Models\n","\n","### Visual Studio Code\n","\n","If you are running these steps below in Visual Studio Code make sure you switch your kernal to Python\n"]},{"cell_type":"code","execution_count":1,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (1.25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.7.1)\n","Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai) (4.11.0)\n","Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n","Requirement already satisfied: colorama in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: panel in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n","Requirement already satisfied: bokeh<3.5.0,>=3.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.4.1)\n","Requirement already satisfied: param<3.0,>=2.0.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (2.1.0)\n","Requirement already satisfied: pyviz-comms>=2.0.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.0.2)\n","Requirement already satisfied: xyzservices>=2021.09.1 in c:\\python312\\lib\\site-packages (from panel) (2024.4.0)\n","Requirement already satisfied: markdown in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.6)\n","Requirement already satisfied: markdown-it-py in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.0.0)\n","Requirement already satisfied: linkify-it-py in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (2.0.3)\n","Requirement already satisfied: mdit-py-plugins in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (0.4.0)\n","Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from panel) (2.31.0)\n","Requirement already satisfied: tqdm>=4.48.0 in c:\\python312\\lib\\site-packages (from panel) (4.66.2)\n","Requirement already satisfied: bleach in c:\\python312\\lib\\site-packages (from panel) (6.1.0)\n","Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from panel) (4.11.0)\n","Requirement already satisfied: pandas>=1.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (2.2.2)\n","Requirement already satisfied: Jinja2>=2.9 in c:\\python312\\lib\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (3.1.3)\n","Requirement already satisfied: contourpy>=1.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (1.2.1)\n","Requirement already satisfied: numpy>=1.16 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (1.26.4)\n","Requirement already satisfied: packaging>=16.8 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (24.0)\n","Requirement already satisfied: pillow>=7.1.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (10.3.0)\n","Requirement already satisfied: PyYAML>=3.10 in c:\\python312\\lib\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (6.0.1)\n","Requirement already satisfied: tornado>=6.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (6.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->panel) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=1.2->panel) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->panel) (2024.1)\n","Requirement already satisfied: colorama in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.48.0->panel) (0.4.6)\n","Requirement already satisfied: six>=1.9.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bleach->panel) (1.16.0)\n","Requirement already satisfied: webencodings in c:\\python312\\lib\\site-packages (from bleach->panel) (0.5.1)\n","Requirement already satisfied: uc-micro-py in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from linkify-it-py->panel) (1.0.3)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py->panel) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->panel) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->panel) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->panel) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->panel) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from Jinja2>=2.9->bokeh<3.5.0,>=3.4.0->panel) (2.1.5)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n","%pip install openai --user\n","%pip install panel --user"]},{"cell_type":"code","execution_count":2,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: openai\n","Version: 1.25.0\n","Summary: The official Python library for the openai API\n","Home-page: \n","Author: \n","Author-email: OpenAI <support@openai.com>\n","License: \n","Location: C:\\Users\\joluedem\\AppData\\Roaming\\Python\\Python312\\site-packages\n","Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n","Required-by: \n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip show openai"]},{"cell_type":"code","execution_count":3,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["https://westus.api.cognitive.microsoft.com/\n","2b6f1904286348cf8936389c0d1df7cc\n","gpt-4\n"]}],"source":["import os\n","from openai import AzureOpenAI\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2024-02-15-preview\"\n",")\n","\n","chatgpt_model_name = os.getenv(\"AOAI_GPT4_DEPLOYMENT\")\n","print(chatgpt_model_name)"]},{"cell_type":"markdown","metadata":{},"source":["Chat models take a series of messages as input, and return a model-generated message as output. The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message)."]},{"cell_type":"code","execution_count":4,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["In the land of code, where logic intertwines,\n","A concept recurs, through the flow of time.\n","Recursion, a dance, a step so divine,\n","A function that calls itself, a self-reflected rhyme.\n","\n","It whispers a question, so simple and pure,\n","\"Shall I invoke myself, once more, once more?\"\n","With each call, a layer, a nesting embrace,\n","Till the base case is met, the recursive grace.\n","\n","A mirror within a mirror, depth without end,\n","Until conditions are met, and it ascends.\n","Back through each layer, unwinding the stack,\n","Returning the answers, from the recursive track.\n","\n","Like Russian dolls, nested one in the next,\n","Each call is contained, in a recursive text.\n","But beware the infinite, the loop without cease,\n","For without a base case, the recursion won't release.\n","\n","So here is the secret, the heart of the spell,\n","A base case to break the infinite well.\n","A condition to stop, to halt the free fall,\n","And give recursion its meaning, its purpose, its all.\n","\n","Thus, in the realm of algorithms and lore,\n","Recursion stands tall, an infinite door.\n","A concept so simple, yet complex to wield,\n","A powerful force in a programmer's field.\n"]}],"source":["# A sample API call for chat completions looks as follows:\n","# Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message).\n","# For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions\n","import openai\n","try:\n","   \n","    response = client.chat.completions.create(\n","    model=chatgpt_model_name,\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n","        {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n","    ],\n","    temperature=0,\n","    max_tokens=800\n","    )\n","\n","    print(response.choices[0].message.content)\n","\n"," \n","except openai.APIError as e:\n","    # Handle API error here, e.g. retry or log\n","    print(f\"OpenAI API returned an API Error: {e}\")\n","\n","except openai.AuthenticationError as e:\n","    # Handle Authentication error here, e.g. invalid API key\n","    print(f\"OpenAI API returned an Authentication Error: {e}\")\n","\n","except openai.APIConnectionError as e:\n","    # Handle connection error here\n","    print(f\"Failed to connect to OpenAI API: {e}\")\n","\n","except openai.RateLimitError as e:\n","    # Handle rate limit error\n","    print(f\"OpenAI API request exceeded rate limit: {e}\")\n","\n","except openai.APITimeoutError as e:\n","    # Handle request timeout\n","    print(f\"Request timed out: {e}\")\n","    \n","except:\n","    # Handles all other exceptions\n","    print(\"An exception has occured.\")"]},{"cell_type":"markdown","metadata":{},"source":["## C# Example:  Setup Parameters"]},{"cell_type":"code","execution_count":14,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/html":["<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>DotNetEnv, 2.5.0</span></li><li><span>Newtonsoft.Json, 13.0.1</span></li><li><span>System.Text.Json, 7.0.3</span></li></ul></div></div>"]},"metadata":{},"output_type":"display_data"}],"source":["#r \"nuget: DotNetEnv, 2.5.0\"\n","#r \"nuget: System.Text.Json, 7.0.3\"\n","#r \"nuget: Newtonsoft.Json, 13.0.1\"\n","using DotNetEnv;\n","\n","using System.Net;\n","using System.Net.Http;\n","using System.Text.Json.Nodes;\n","using System.Text.Json;\n","\n","static string _configurationFile = @\"../.env\";\n","Env.Load(_configurationFile);\n","\n","string apiBase = Environment.GetEnvironmentVariable(\"AOAI_ENDPOINT\"); \n","string apiKey = Environment.GetEnvironmentVariable(\"AOAI_APIKEY\"); \n","string deploymentName = Environment.GetEnvironmentVariable(\"AOAI_GPT4_DEPLOYMENT\"); \n","string apiVersion = \"2023-07-01-preview\";"]},{"cell_type":"markdown","metadata":{},"source":["Expected output\n","```\n","Installed Packages\n","    DotNetEnv, 2.5.0\n","    Newtonsoft.Json, 13.0.1\n","    System.Text.Json, 7.0.3\n","```"]},{"cell_type":"code","execution_count":15,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["https://westus.api.cognitive.microsoft.com/\n","gpt-4\n"]}],"source":["Console.WriteLine(apiBase);\n","// Console.WriteLine(apiKey);\n","Console.WriteLine(deploymentName);\n"]},{"cell_type":"markdown","metadata":{},"source":["## Create completions for chat messages with GPT models\n","\n","The code cell is using an instance of `HttpClient` to call the REST API of the deployed Azure OpenAI instance."]},{"cell_type":"code","execution_count":16,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Output: It seems you are experiencing issues with receiving calls on your Samsung Galaxy S22 and you're seeking assistance to resolve this problem.\r\n"]}],"source":["var requestPayload = new JsonObject\n","{\n","    { \"messages\", new JsonArray\n","        {\n","            new JsonObject\n","            {\n","                { \"role\", \"system\" },\n","                { \"content\", \"You are an AI assistance who You extract intention from provided text. You always answer with intention:\" }\n","                \n","            },\n","            new JsonObject\n","            {\n","                { \"role\", \"user\" },\n","                { \"content\", \"I'm not receiving calls on my Samsung Galaxy S22. Can you help?\" }\n","            }\n","        }\n","    },\n","    { \"max_tokens\", 200 },\n","    { \"temperature\", 0.7 },\n","    { \"frequency_penalty\", 0 },\n","    { \"presence_penalty\", 0 },\n","    { \"top_p\", 0.95 },\n","    { \"stop\", null }\n","};\n","\n","string payload = JsonSerializer.Serialize(requestPayload, new JsonSerializerOptions\n","{\n","    WriteIndented = true // Optional: to make the JSON string more readable\n","});\n","\n","        \n","string endpoint = $\"{apiBase}openai/deployments/{deploymentName}/chat/completions?api-version={apiVersion}\";\n","\n","using (HttpClient httpClient = new HttpClient())\n","{\n","    httpClient.BaseAddress = new Uri(endpoint);\n","    httpClient.DefaultRequestHeaders.Add(\"api-key\",apiKey);\n","    httpClient.DefaultRequestHeaders.Accept.Add(new System.Net.Http.Headers.MediaTypeWithQualityHeaderValue(\"application/json\"));\n","\n","    var stringContent = new StringContent(payload, Encoding.UTF8, \"application/json\");\n","\n","    var response = await httpClient.PostAsync(endpoint, stringContent);\n","\n","    if (response.IsSuccessStatusCode)\n","    {\n","        using (var responseStream = await response.Content.ReadAsStreamAsync())\n","        {\n","            // Parse the JSON response using JsonDocument\n","            using (var jsonDoc = await JsonDocument.ParseAsync(responseStream))\n","            {\n","                // Access the message content dynamically\n","                var root = jsonDoc.RootElement;\n","                var messageContent = root.GetProperty(\"choices\")[0].GetProperty(\"message\").GetProperty(\"content\").GetString();\n","\n","                // Output the message content\n","                Console.WriteLine(\"Output: \" + messageContent);\n","            }\n","        }\n","    }\n","    else\n","    {\n","        Console.WriteLine($\"Error: {response}\");\n","    }\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Output: Intention: Requesting technical assistance with phone call issue on Samsung Galaxy S22.\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 3.4 Tokenization\n","\n","In this notebook, we'll explore basic concepts behind tokenization, how to use the Microsoft.ML.Tokenizers library to tokenize text and get information about token counts\n","\n","https://github.com/Azure-Samples/openai-dotnet-samples/blob/main/tokenization.ipynb"]},{"cell_type":"markdown","metadata":{},"source":["### Install Microsoft.ML.Tokenizers"]},{"cell_type":"code","execution_count":17,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/html":["<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Microsoft.ML.Tokenizers, 0.21.1</span></li></ul></div></div>"]},"metadata":{},"output_type":"display_data"}],"source":["#r \"nuget:Microsoft.ML.Tokenizers\""]},{"cell_type":"markdown","metadata":{},"source":["Installed Packages\n"," - Microsoft.ML.Tokenizers, 0.21.1"]},{"cell_type":"markdown","metadata":{},"source":["### Add using statements"]},{"cell_type":"code","execution_count":18,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["using Microsoft.ML.Tokenizers;"]},{"cell_type":"markdown","metadata":{},"source":["### Download and define vocab resources\n","\n","Download the following files and place them in the root directory. These vocabulary files are what are used to encode the text into tokens.\n","\n","- [GPT Vocabulary Files](https://huggingface.co/gpt2/tree/main)\n","    - vocab.json\n","    - merges.txt"]},{"cell_type":"code","execution_count":19,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var vocabFilePath = @\"../notebooks/assets/vocab.json\";\n","var mergeFilePath = @\"../notebooks/assets/merges.txt\";"]},{"cell_type":"markdown","metadata":{},"source":["### Initialize Tokenizer"]},{"cell_type":"code","execution_count":20,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var tokenizer = new Tokenizer(new Bpe(vocabFilePath, mergeFilePath));"]},{"cell_type":"markdown","metadata":{},"source":["### Encode text into tokens"]},{"cell_type":"code","execution_count":21,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/html":["<details open=\"open\" class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>Microsoft.ML.Tokenizers.TokenizerResult</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>OriginalString</td><td><div class=\"dni-plaintext\"><pre>the brown fox jumped over the lazy dog!</pre></div></td></tr><tr><td>NormalizedString</td><td><div class=\"dni-plaintext\"><pre>the brown fox jumped over the lazy dog!</pre></div></td></tr><tr><td>OffsetsMappedToOriginalString</td><td><div class=\"dni-plaintext\"><pre>True</pre></div></td></tr><tr><td>Ids</td><td><div class=\"dni-plaintext\"><pre>[ 1169, 33282, 12792, 73, 27073, 2502, 1169, 75, 12582, 9703, 0 ]</pre></div></td></tr><tr><td>Tokens</td><td><div class=\"dni-plaintext\"><pre>[ the, brown, fox, j, umped, over, the, l, azy, dog, ! ]</pre></div></td></tr><tr><td>Offsets</td><td><table><thead><tr><th><i>index</i></th><th>value</th></tr></thead><tbody><tr><td>0</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(0, 3)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>0</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>3</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>1</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(4, 9)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>4</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>9</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>2</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(10, 13)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>10</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>13</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>3</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(14, 15)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>14</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>15</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>4</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(15, 20)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>15</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>20</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>5</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(21, 25)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>21</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>25</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>6</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(26, 29)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>26</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>29</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>7</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(30, 31)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>30</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>31</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>8</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(31, 34)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>31</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>34</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>9</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(35, 38)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>35</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>38</pre></div></td></tr></tbody></table></div></details></td></tr><tr><td>10</td><td><details class=\"dni-treeview\"><summary><span class=\"dni-code-hint\"><code>(38, 39)</code></span></summary><div><table><thead><tr></tr></thead><tbody><tr><td>Item1</td><td><div class=\"dni-plaintext\"><pre>38</pre></div></td></tr><tr><td>Item2</td><td><div class=\"dni-plaintext\"><pre>39</pre></div></td></tr></tbody></table></div></details></td></tr></tbody></table></td></tr></tbody></table></div></details><style>\r\n",".dni-code-hint {\r\n","    font-style: italic;\r\n","    overflow: hidden;\r\n","    white-space: nowrap;\r\n","}\r\n",".dni-treeview {\r\n","    white-space: nowrap;\r\n","}\r\n",".dni-treeview td {\r\n","    vertical-align: top;\r\n","    text-align: start;\r\n","}\r\n","details.dni-treeview {\r\n","    padding-left: 1em;\r\n","}\r\n","table td {\r\n","    text-align: start;\r\n","}\r\n","table tr { \r\n","    vertical-align: top; \r\n","    margin: 0em 0px;\r\n","}\r\n","table tr td pre \r\n","{ \r\n","    vertical-align: top !important; \r\n","    margin: 0em 0px !important;\r\n","} \r\n","table th {\r\n","    text-align: start;\r\n","}\r\n","</style>"]},"metadata":{},"output_type":"display_data"}],"source":["var input = \"the brown fox jumped over the lazy dog!\";\n","var tokenizerEncodedResult = tokenizer.Encode(input);\n","tokenizerEncodedResult"]},{"cell_type":"markdown","metadata":{},"source":["### Get token count"]},{"cell_type":"code","execution_count":22,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/html":["<div class=\"dni-plaintext\"><pre>11</pre></div><style>\r\n",".dni-code-hint {\r\n","    font-style: italic;\r\n","    overflow: hidden;\r\n","    white-space: nowrap;\r\n","}\r\n",".dni-treeview {\r\n","    white-space: nowrap;\r\n","}\r\n",".dni-treeview td {\r\n","    vertical-align: top;\r\n","    text-align: start;\r\n","}\r\n","details.dni-treeview {\r\n","    padding-left: 1em;\r\n","}\r\n","table td {\r\n","    text-align: start;\r\n","}\r\n","table tr { \r\n","    vertical-align: top; \r\n","    margin: 0em 0px;\r\n","}\r\n","table tr td pre \r\n","{ \r\n","    vertical-align: top !important; \r\n","    margin: 0em 0px !important;\r\n","} \r\n","table th {\r\n","    text-align: start;\r\n","}\r\n","</style>"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizerEncodedResult.Tokens.Count()"]},{"cell_type":"markdown","metadata":{},"source":["# 3.5 Prompts & Completions\n","\n","In this section, we'll explore small prompt engineering techniques, prompt construction, and recommendations that will help us elicit responses from the models that are better suited to our needs. In addition, the techniques in this section will teach you strategies for increasing the accuracy and grounding of responses you generate with a Large Language Model (LLM)."]},{"cell_type":"code","execution_count":5,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: openai in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (1.25.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai) (0.27.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from openai) (2.7.1)\n","Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai) (4.11.0)\n","Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n","Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n","Requirement already satisfied: colorama in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: panel in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (1.4.2)\n","Requirement already satisfied: bokeh<3.5.0,>=3.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.4.1)\n","Requirement already satisfied: param<3.0,>=2.0.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (2.1.0)\n","Requirement already satisfied: pyviz-comms>=2.0.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.0.2)\n","Requirement already satisfied: xyzservices>=2021.09.1 in c:\\python312\\lib\\site-packages (from panel) (2024.4.0)\n","Requirement already satisfied: markdown in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.6)\n","Requirement already satisfied: markdown-it-py in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (3.0.0)\n","Requirement already satisfied: linkify-it-py in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (2.0.3)\n","Requirement already satisfied: mdit-py-plugins in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (0.4.0)\n","Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from panel) (2.31.0)\n","Requirement already satisfied: tqdm>=4.48.0 in c:\\python312\\lib\\site-packages (from panel) (4.66.2)\n","Requirement already satisfied: bleach in c:\\python312\\lib\\site-packages (from panel) (6.1.0)\n","Requirement already satisfied: typing-extensions in c:\\python312\\lib\\site-packages (from panel) (4.11.0)\n","Requirement already satisfied: pandas>=1.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from panel) (2.2.2)\n","Requirement already satisfied: Jinja2>=2.9 in c:\\python312\\lib\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (3.1.3)\n","Requirement already satisfied: contourpy>=1.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (1.2.1)\n","Requirement already satisfied: numpy>=1.16 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (1.26.4)\n","Requirement already satisfied: packaging>=16.8 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (24.0)\n","Requirement already satisfied: pillow>=7.1.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (10.3.0)\n","Requirement already satisfied: PyYAML>=3.10 in c:\\python312\\lib\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (6.0.1)\n","Requirement already satisfied: tornado>=6.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bokeh<3.5.0,>=3.4.0->panel) (6.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->panel) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas>=1.2->panel) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.2->panel) (2024.1)\n","Requirement already satisfied: colorama in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.48.0->panel) (0.4.6)\n","Requirement already satisfied: six>=1.9.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from bleach->panel) (1.16.0)\n","Requirement already satisfied: webencodings in c:\\python312\\lib\\site-packages (from bleach->panel) (0.5.1)\n","Requirement already satisfied: uc-micro-py in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from linkify-it-py->panel) (1.0.3)\n","Requirement already satisfied: mdurl~=0.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from markdown-it-py->panel) (0.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->panel) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->panel) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->panel) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->panel) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from Jinja2>=2.9->bokeh<3.5.0,>=3.4.0->panel) (2.1.5)\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting semantic_kernel\n","  Downloading semantic_kernel-0.9.6b1-py3-none-any.whl.metadata (5.2 kB)\n","Collecting aiohttp<4.0,>=3.8 (from semantic_kernel)\n","  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\python312\\lib\\site-packages (from semantic_kernel) (0.7.1)\n","Collecting grpcio>=1.50.0 (from semantic_kernel)\n","  Downloading grpcio-1.63.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n","Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\python312\\lib\\site-packages (from semantic_kernel) (3.1.3)\n","Collecting motor<4.0.0,>=3.3.2 (from semantic_kernel)\n","  Downloading motor-3.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (1.6.0)\n","Requirement already satisfied: numpy>=1.26 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (1.26.4)\n","Requirement already satisfied: openai>=1.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (1.25.0)\n","Collecting openapi_core<0.20,>=0.18 (from semantic_kernel)\n","  Downloading openapi_core-0.19.1-py3-none-any.whl.metadata (6.4 kB)\n","Collecting prance<24.0.0.0,>=23.6.21.0 (from semantic_kernel)\n","  Downloading prance-23.6.21.0-py3-none-any.whl.metadata (13 kB)\n","Collecting pybars4<0.10.0,>=0.9.13 (from semantic_kernel)\n","  Downloading pybars4-0.9.13.tar.gz (29 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: pydantic<3,>=2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (2.7.1)\n","Collecting python-dotenv<2.0.0,>=1.0.1 (from semantic_kernel)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Collecting regex<2024.0.0,>=2023.6.3 (from semantic_kernel)\n","  Downloading regex-2023.12.25-cp312-cp312-win_amd64.whl.metadata (41 kB)\n","     ---------------------------------------- 0.0/42.0 kB ? eta -:--:--\n","     ---------------------------------------- 42.0/42.0 kB 1.0 MB/s eta 0:00:00\n","Collecting scipy>=1.12.0 (from semantic_kernel)\n","  Downloading scipy-1.13.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n","     ---------------------------------------- 0.0/60.6 kB ? eta -:--:--\n","     ---------------------------------------- 60.6/60.6 kB 3.1 MB/s eta 0:00:00\n","Collecting aiosignal>=1.1.2 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (23.2.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic_kernel) (2.1.5)\n","Collecting pymongo<5,>=4.5 (from motor<4.0.0,>=3.3.2->semantic_kernel)\n","  Downloading pymongo-4.7.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic_kernel) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (0.27.0)\n","Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (1.3.1)\n","Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.11.0)\n","Collecting isodate (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (4.22.0)\n","Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading jsonschema_path-0.3.2-py3-none-any.whl.metadata (4.3 kB)\n","Collecting more-itertools (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n","Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading openapi_schema_validator-0.6.2-py3-none-any.whl.metadata (5.3 kB)\n","Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading openapi_spec_validator-0.7.1-py3-none-any.whl.metadata (5.7 kB)\n","Collecting parse (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading parse-1.20.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting werkzeug (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading werkzeug-3.0.2-py3-none-any.whl.metadata (4.1 kB)\n","Collecting chardet>=3.0 (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel)\n","  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n","Collecting ruamel.yaml>=0.17.10 (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel)\n","  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: requests>=2.25 in c:\\python312\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.31.0)\n","Requirement already satisfied: six~=1.15 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (1.16.0)\n","Requirement already satisfied: packaging>=21.3 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (24.0)\n","Collecting PyMeta3>=0.5.1 (from pybars4<0.10.0,>=0.9.13->semantic_kernel)\n","  Downloading PyMeta3-0.5.1.tar.gz (29 kB)\n","  Installing build dependencies: started\n","  Installing build dependencies: finished with status 'done'\n","  Getting requirements to build wheel: started\n","  Getting requirements to build wheel: finished with status 'done'\n","  Installing backend dependencies: started\n","  Installing backend dependencies: finished with status 'done'\n","  Preparing metadata (pyproject.toml): started\n","  Preparing metadata (pyproject.toml): finished with status 'done'\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=2->semantic_kernel) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=2->semantic_kernel) (2.18.2)\n","Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic_kernel) (3.7)\n","Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (0.14.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.35.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.18.0)\n","Requirement already satisfied: PyYAML>=5.1 in c:\\python312\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic_kernel) (6.0.1)\n","Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading pathable-0.4.3-py3-none-any.whl.metadata (1.9 kB)\n","Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading referencing-0.31.1-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: rfc3339-validator in c:\\python312\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.1.4)\n","Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic_kernel)\n","  Downloading lazy_object_proxy-1.10.0-cp312-cp312-win_amd64.whl.metadata (8.1 kB)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic_kernel)\n","  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.2.1)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic_kernel)\n","  Downloading ruamel.yaml.clib-0.2.8-cp312-cp312-win_amd64.whl.metadata (2.3 kB)\n","Requirement already satisfied: colorama in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.0->semantic_kernel) (0.4.6)\n","Downloading semantic_kernel-0.9.6b1-py3-none-any.whl (273 kB)\n","   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n","   ----------------------- ---------------- 163.8/273.6 kB 5.0 MB/s eta 0:00:01\n","   ---------------------------------------- 273.6/273.6 kB 3.4 MB/s eta 0:00:00\n","Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n","   ---------------------------------------- 0.0/369.0 kB ? eta -:--:--\n","   ------------------ --------------------- 174.1/369.0 kB 5.3 MB/s eta 0:00:01\n","   ---------------------------------------  368.6/369.0 kB 4.6 MB/s eta 0:00:01\n","   ---------------------------------------- 369.0/369.0 kB 3.9 MB/s eta 0:00:00\n","Downloading grpcio-1.63.0-cp312-cp312-win_amd64.whl (3.9 MB)\n","   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n","   -- ------------------------------------- 0.2/3.9 MB 4.6 MB/s eta 0:00:01\n","   ----- ---------------------------------- 0.5/3.9 MB 5.4 MB/s eta 0:00:01\n","   -------- ------------------------------- 0.8/3.9 MB 5.8 MB/s eta 0:00:01\n","   ------------ --------------------------- 1.2/3.9 MB 6.5 MB/s eta 0:00:01\n","   ---------------- ----------------------- 1.6/3.9 MB 6.9 MB/s eta 0:00:01\n","   --------------------- ------------------ 2.1/3.9 MB 7.5 MB/s eta 0:00:01\n","   -------------------------- ------------- 2.6/3.9 MB 8.0 MB/s eta 0:00:01\n","   -------------------------------- ------- 3.2/3.9 MB 8.4 MB/s eta 0:00:01\n","   ---------------------------------------  3.8/3.9 MB 9.0 MB/s eta 0:00:01\n","   ---------------------------------------- 3.9/3.9 MB 8.6 MB/s eta 0:00:00\n","Downloading motor-3.4.0-py3-none-any.whl (74 kB)\n","   ---------------------------------------- 0.0/74.3 kB ? eta -:--:--\n","   ---------------------------------------- 74.3/74.3 kB 4.3 MB/s eta 0:00:00\n","Downloading openapi_core-0.19.1-py3-none-any.whl (103 kB)\n","   ---------------------------------------- 0.0/103.1 kB ? eta -:--:--\n","   ---------------------------------------- 103.1/103.1 kB 6.2 MB/s eta 0:00:00\n","Downloading prance-23.6.21.0-py3-none-any.whl (36 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading regex-2023.12.25-cp312-cp312-win_amd64.whl (268 kB)\n","   ---------------------------------------- 0.0/268.9 kB ? eta -:--:--\n","   ---------------------------------------- 268.9/268.9 kB 8.3 MB/s eta 0:00:00\n","Downloading scipy-1.13.0-cp312-cp312-win_amd64.whl (45.9 MB)\n","   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n","    --------------------------------------- 0.7/45.9 MB 14.6 MB/s eta 0:00:04\n","   - -------------------------------------- 1.5/45.9 MB 15.7 MB/s eta 0:00:03\n","   -- ------------------------------------- 2.4/45.9 MB 17.1 MB/s eta 0:00:03\n","   --- ------------------------------------ 3.5/45.9 MB 18.4 MB/s eta 0:00:03\n","   ---- ----------------------------------- 4.6/45.9 MB 19.6 MB/s eta 0:00:03\n","   ----- ---------------------------------- 5.8/45.9 MB 20.6 MB/s eta 0:00:02\n","   ------ --------------------------------- 7.2/45.9 MB 21.9 MB/s eta 0:00:02\n","   ------- -------------------------------- 9.0/45.9 MB 23.9 MB/s eta 0:00:02\n","   --------- ------------------------------ 10.9/45.9 MB 27.3 MB/s eta 0:00:02\n","   ----------- ---------------------------- 12.9/45.9 MB 32.8 MB/s eta 0:00:02\n","   ------------- -------------------------- 15.1/45.9 MB 36.4 MB/s eta 0:00:01\n","   --------------- ------------------------ 17.6/45.9 MB 43.7 MB/s eta 0:00:01\n","   ----------------- ---------------------- 20.3/45.9 MB 50.4 MB/s eta 0:00:01\n","   -------------------- ------------------- 23.4/45.9 MB 59.5 MB/s eta 0:00:01\n","   ----------------------- ---------------- 26.7/45.9 MB 65.6 MB/s eta 0:00:01\n","   -------------------------- ------------- 30.3/45.9 MB 72.6 MB/s eta 0:00:01\n","   ----------------------------- ---------- 34.2/45.9 MB 81.8 MB/s eta 0:00:01\n","   --------------------------------- ------ 38.4/45.9 MB 81.8 MB/s eta 0:00:01\n","   ------------------------------------- -- 43.4/45.9 MB 93.9 MB/s eta 0:00:01\n","   ---------------------------------------  44.9/45.9 MB 81.8 MB/s eta 0:00:01\n","   ---------------------------------------  45.9/45.9 MB 72.6 MB/s eta 0:00:01\n","   ---------------------------------------  45.9/45.9 MB 72.6 MB/s eta 0:00:01\n","   ---------------------------------------- 45.9/45.9 MB 43.5 MB/s eta 0:00:00\n","Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n","   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n","   --------------------------------------- 199.4/199.4 kB 11.8 MB/s eta 0:00:00\n","Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n","   ---------------------------------------- 0.0/50.5 kB ? eta -:--:--\n","   ---------------------------------------- 50.5/50.5 kB ? eta 0:00:00\n","Downloading jsonschema_path-0.3.2-py3-none-any.whl (14 kB)\n","Downloading multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n","Downloading openapi_schema_validator-0.6.2-py3-none-any.whl (8.8 kB)\n","Downloading openapi_spec_validator-0.7.1-py3-none-any.whl (38 kB)\n","Downloading pymongo-4.7.1-cp312-cp312-win_amd64.whl (484 kB)\n","   ---------------------------------------- 0.0/485.0 kB ? eta -:--:--\n","   ---------------------------------------- 485.0/485.0 kB ? eta 0:00:00\n","Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n","   ---------------------------------------- 0.0/117.8 kB ? eta -:--:--\n","   ---------------------------------------- 117.8/117.8 kB ? eta 0:00:00\n","Downloading yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n","   ---------------------------------------- 0.0/76.4 kB ? eta -:--:--\n","   ---------------------------------------- 76.4/76.4 kB 4.4 MB/s eta 0:00:00\n","Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","   ---------------------------------------- 0.0/41.7 kB ? eta -:--:--\n","   ---------------------------------------- 41.7/41.7 kB 2.0 MB/s eta 0:00:00\n","Downloading more_itertools-10.2.0-py3-none-any.whl (57 kB)\n","   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n","   ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n","Downloading parse-1.20.1-py2.py3-none-any.whl (20 kB)\n","Downloading werkzeug-3.0.2-py3-none-any.whl (226 kB)\n","   ---------------------------------------- 0.0/226.8 kB ? eta -:--:--\n","   --------------------------------------- 226.8/226.8 kB 14.4 MB/s eta 0:00:00\n","Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n","   --------------------------------------- 307.7/307.7 kB 18.6 MB/s eta 0:00:00\n","Downloading lazy_object_proxy-1.10.0-cp312-cp312-win_amd64.whl (27 kB)\n","Downloading pathable-0.4.3-py3-none-any.whl (9.6 kB)\n","Downloading referencing-0.31.1-py3-none-any.whl (25 kB)\n","Downloading ruamel.yaml.clib-0.2.8-cp312-cp312-win_amd64.whl (115 kB)\n","   ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n","   ---------------------------------------- 115.3/115.3 kB ? eta 0:00:00\n","Building wheels for collected packages: pybars4, PyMeta3\n","  Building wheel for pybars4 (pyproject.toml): started\n","  Building wheel for pybars4 (pyproject.toml): finished with status 'done'\n","  Created wheel for pybars4: filename=pybars4-0.9.13-py3-none-any.whl size=14349 sha256=47242264f9ce2dc012e9e3b94fb5bb6c51fc608982c9584262748d59413fc677\n","  Stored in directory: c:\\users\\joluedem\\appdata\\local\\pip\\cache\\wheels\\75\\2d\\da\\c75b2fc7b00dc9c154dff65f689a318e7d24b44c612c2b21f1\n","  Building wheel for PyMeta3 (pyproject.toml): started\n","  Building wheel for PyMeta3 (pyproject.toml): finished with status 'done'\n","  Created wheel for PyMeta3: filename=PyMeta3-0.5.1-py3-none-any.whl size=16487 sha256=4df097294174a71132e8c8e7cec8b3f155eeea6a34ad860121fc4afb25e7e613\n","  Stored in directory: c:\\users\\joluedem\\appdata\\local\\pip\\cache\\wheels\\5a\\9b\\2c\\81b7551d2c05a482817e6c3b3d2f8ad2a0229db874c4bc6346\n","Successfully built pybars4 PyMeta3\n","Installing collected packages: PyMeta3, parse, werkzeug, scipy, ruamel.yaml.clib, regex, referencing, python-dotenv, pybars4, pathable, multidict, more-itertools, lazy-object-proxy, isodate, grpcio, frozenlist, dnspython, chardet, yarl, ruamel.yaml, pymongo, jsonschema-path, aiosignal, prance, motor, aiohttp, openapi-schema-validator, openapi-spec-validator, openapi_core, semantic_kernel\n","  Attempting uninstall: referencing\n","    Found existing installation: referencing 0.35.0\n","    Uninstalling referencing-0.35.0:\n","      Successfully uninstalled referencing-0.35.0\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: Failed to write executable - trying to use .deleteme logic\n","ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python312\\\\Scripts\\\\dotenv.exe' -> 'c:\\\\Python312\\\\Scripts\\\\dotenv.exe.deleteme'\n","\n"]}],"source":["%pip install openai\n","%pip install panel \n","%pip install semantic_kernel\n","%pip install common"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: common in c:\\python312\\lib\\site-packages (0.1.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting semantic_kernel\n","  Using cached semantic_kernel-0.9.6b1-py3-none-any.whl.metadata (5.2 kB)\n","Collecting aiohttp<4.0,>=3.8 (from semantic_kernel)\n","  Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\python312\\lib\\site-packages (from semantic_kernel) (0.7.1)\n","Collecting grpcio>=1.50.0 (from semantic_kernel)\n","  Using cached grpcio-1.63.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n","Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\python312\\lib\\site-packages (from semantic_kernel) (3.1.3)\n","Collecting motor<4.0.0,>=3.3.2 (from semantic_kernel)\n","  Using cached motor-3.4.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (1.6.0)\n","Requirement already satisfied: numpy>=1.26 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (1.26.4)\n","Requirement already satisfied: openai>=1.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (1.25.0)\n","Collecting openapi_core<0.20,>=0.18 (from semantic_kernel)\n","  Using cached openapi_core-0.19.1-py3-none-any.whl.metadata (6.4 kB)\n","Collecting prance<24.0.0.0,>=23.6.21.0 (from semantic_kernel)\n","  Using cached prance-23.6.21.0-py3-none-any.whl.metadata (13 kB)\n","Collecting pybars4<0.10.0,>=0.9.13 (from semantic_kernel)\n","  Using cached pybars4-0.9.13-py3-none-any.whl\n","Requirement already satisfied: pydantic<3,>=2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from semantic_kernel) (2.7.1)\n","Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\python312\\lib\\site-packages (from semantic_kernel) (1.0.1)\n","Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in c:\\python312\\lib\\site-packages (from semantic_kernel) (2023.12.25)\n","Requirement already satisfied: scipy>=1.12.0 in c:\\python312\\lib\\site-packages (from semantic_kernel) (1.13.0)\n","Collecting aiosignal>=1.1.2 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\python312\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (23.2.0)\n","Collecting frozenlist>=1.1.1 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n","Collecting multidict<7.0,>=4.5 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp<4.0,>=3.8->semantic_kernel)\n","  Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl.metadata (32 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic_kernel) (2.1.5)\n","Collecting pymongo<5,>=4.5 (from motor<4.0.0,>=3.3.2->semantic_kernel)\n","  Using cached pymongo-4.7.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n","Requirement already satisfied: anyio<5,>=3.5.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.3.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0->semantic_kernel) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (0.27.0)\n","Requirement already satisfied: sniffio in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (1.3.1)\n","Requirement already satisfied: tqdm>4 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.66.2)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\python312\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.11.0)\n","Collecting isodate (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached isodate-0.6.1-py2.py3-none-any.whl.metadata (9.6 kB)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (4.22.0)\n","Collecting jsonschema-path<0.4.0,>=0.3.1 (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached jsonschema_path-0.3.2-py3-none-any.whl.metadata (4.3 kB)\n","Collecting more-itertools (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached more_itertools-10.2.0-py3-none-any.whl.metadata (34 kB)\n","Collecting openapi-schema-validator<0.7.0,>=0.6.0 (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached openapi_schema_validator-0.6.2-py3-none-any.whl.metadata (5.3 kB)\n","Collecting openapi-spec-validator<0.8.0,>=0.7.1 (from openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached openapi_spec_validator-0.7.1-py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: parse in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (1.20.1)\n","Requirement already satisfied: werkzeug in c:\\python312\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (3.0.2)\n","Collecting chardet>=3.0 (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel)\n","  Using cached chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n","Collecting ruamel.yaml>=0.17.10 (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel)\n","  Using cached ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: requests>=2.25 in c:\\python312\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.31.0)\n","Requirement already satisfied: six~=1.15 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (1.16.0)\n","Requirement already satisfied: packaging>=21.3 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (24.0)\n","Requirement already satisfied: PyMeta3>=0.5.1 in c:\\python312\\lib\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic_kernel) (0.5.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=2->semantic_kernel) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=2->semantic_kernel) (2.18.2)\n","Requirement already satisfied: idna>=2.8 in c:\\python312\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic_kernel) (3.7)\n","Requirement already satisfied: certifi in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in c:\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (1.0.5)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (0.14.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.31.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in c:\\python312\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.18.0)\n","Requirement already satisfied: PyYAML>=5.1 in c:\\python312\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic_kernel) (6.0.1)\n","Collecting pathable<0.5.0,>=0.4.1 (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached pathable-0.4.3-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: rfc3339-validator in c:\\python312\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.1.4)\n","Collecting lazy-object-proxy<2.0.0,>=1.7.1 (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic_kernel)\n","  Using cached lazy_object_proxy-1.10.0-cp312-cp312-win_amd64.whl.metadata (8.1 kB)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic_kernel)\n","  Using cached dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (3.3.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.2.1)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in c:\\python312\\lib\\site-packages (from ruamel.yaml>=0.17.10->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (0.2.8)\n","Requirement already satisfied: colorama in c:\\users\\joluedem\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>4->openai>=1.0->semantic_kernel) (0.4.6)\n","Using cached semantic_kernel-0.9.6b1-py3-none-any.whl (273 kB)\n","Using cached aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n","Using cached grpcio-1.63.0-cp312-cp312-win_amd64.whl (3.9 MB)\n","Using cached motor-3.4.0-py3-none-any.whl (74 kB)\n","Using cached openapi_core-0.19.1-py3-none-any.whl (103 kB)\n","Using cached prance-23.6.21.0-py3-none-any.whl (36 kB)\n","Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n","Using cached frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n","Using cached jsonschema_path-0.3.2-py3-none-any.whl (14 kB)\n","Using cached multidict-6.0.5-cp312-cp312-win_amd64.whl (27 kB)\n","Using cached openapi_schema_validator-0.6.2-py3-none-any.whl (8.8 kB)\n","Using cached openapi_spec_validator-0.7.1-py3-none-any.whl (38 kB)\n","Using cached pymongo-4.7.1-cp312-cp312-win_amd64.whl (484 kB)\n","Using cached ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n","Using cached yarl-1.9.4-cp312-cp312-win_amd64.whl (76 kB)\n","Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n","Using cached more_itertools-10.2.0-py3-none-any.whl (57 kB)\n","Using cached dnspython-2.6.1-py3-none-any.whl (307 kB)\n","Using cached lazy_object_proxy-1.10.0-cp312-cp312-win_amd64.whl (27 kB)\n","Using cached pathable-0.4.3-py3-none-any.whl (9.6 kB)\n","Installing collected packages: ruamel.yaml, pybars4, pathable, multidict, more-itertools, lazy-object-proxy, isodate, grpcio, frozenlist, dnspython, chardet, yarl, pymongo, prance, jsonschema-path, aiosignal, motor, aiohttp, openapi-schema-validator, openapi-spec-validator, openapi_core, semantic_kernel\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: Failed to write executable - trying to use .deleteme logic\n","ERROR: Could not install packages due to an OSError: [WinError 2] The system cannot find the file specified: 'c:\\\\Python312\\\\Scripts\\\\chardetect.exe' -> 'c:\\\\Python312\\\\Scripts\\\\chardetect.exe.deleteme'\n","\n"]}],"source":["%pip install common \n","%pip install semantic_kernel"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import os\n","from openai import AzureOpenAI\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2024-02-15-preview\"\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEFFb3yPuNiNv4T834xmBQydtjwG\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975.\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608345,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 18,\n","    \"prompt_tokens\": 29,\n","    \"total_tokens\": 47\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Microsoft was founded by Bill Gates and Paul Allen on April 4, 1975.\n"]}],"source":["response = client.chat.completions.create(\n","    model=\"gpt-35-turbo\", # model = \"deployment_name\".\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n","        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n","    ]\n",")\n","\n","#print(response)\n","print(response.model_dump_json(indent=2))\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["# 3.6 Techniques\n","\n","In this section, we'll delve into techniques designed to enhance the accuracy and coherence of responses generated by a Large Language Model (LLM). These strategies will equip you with the skills to produce more precise and well-grounded outputs."]},{"cell_type":"markdown","metadata":{},"source":["# Formating the answer with Few Shot Samples.\n","\n","To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n","\n","Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n","\n","Depending on the number of examples given, this technique can be referred to as:\n","* Zero-Shot - which refers to providing no examples\n","* One-Shot.\n","* Few-Shots - The term few-shot refers to providing a few of examples to help the model learn what it needs to do\n","\n","With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n"]},{"cell_type":"code","execution_count":8,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["#Functio to call the model.\n","def return_OAIResponse(user_message, context):\n","\n","#As we can see, we’re adding the user’s question at the end of the prompt with the user role, so the model understands that this is a user request and not an instruction on how it should work.\n","    newcontext = context.copy()\n","    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n","\n","    # print(newcontext)\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-35-turbo\", # model = \"deployment_name\".\n","        messages=newcontext,\n","        temperature=0,\n","        max_tokens=800\n","    )\n","\n","    # print(response)\n","    print(response.model_dump_json(indent=2))\n","\n","    return (response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."]},{"cell_type":"code","execution_count":9,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEGEDL3Yv7tAJlE0B72vjgNoIseD\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Sebastian Vettel won the F1 2010 championship.\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608406,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 13,\n","    \"prompt_tokens\": 30,\n","    \"total_tokens\": 43\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Sebastian Vettel won the F1 2010 championship.\n"]}],"source":["#zero-shot\n","context_user = [\n","    {'role':'system', 'content':'You are an expert in F1.'}\n","]\n","print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"]},{"cell_type":"code","execution_count":10,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEHEAxhd0mfyzhldufInTPeLnm2q\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Driver: Sebastian Vettel\\nTeam: Red Bull Racing\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608468,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 11,\n","    \"prompt_tokens\": 54,\n","    \"total_tokens\": 65\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Driver: Sebastian Vettel\n","Team: Red Bull Racing\n"]}],"source":["#one-shot\n","context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in F1.\n","\n","     Who won the 2000 f1 championship?\n","     Driver: Michael Schumacher.\n","     Team: Ferrari.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."]},{"cell_type":"code","execution_count":11,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEICZ7FwuOgjw4kt96uzL8SXtHRU\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"The 2006 F1 championship was won by Fernando Alonso, driving for the Renault F1 Team.\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608528,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 21,\n","    \"prompt_tokens\": 80,\n","    \"total_tokens\": 101\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","The 2006 F1 championship was won by Fernando Alonso, driving for the Renault F1 Team.\n"]}],"source":["#Few shots\n","context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in F1.\n","\n","     Who won the 2010 f1 championship?\n","     Driver: Sebastian Bettel.\n","     Team: Red Bull Renault.\n","\n","     Who won the 2009 f1 championship?\n","     Driver: Jenson Button.\n","     Team: BrawnGP.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"]},{"cell_type":"code","execution_count":12,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEJBxIu76OtYHa8JmwbJMCJ5UPPo\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"The 2019 F1 championship was won by Lewis Hamilton, driving for Mercedes.\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608589,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 17,\n","    \"prompt_tokens\": 80,\n","    \"total_tokens\": 97\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","The 2019 F1 championship was won by Lewis Hamilton, driving for Mercedes.\n"]}],"source":["print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n","\n","However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n","\n","By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."]},{"cell_type":"code","execution_count":13,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEKRTY37pjKR87mjB0vNNU3meut5\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Lewis Hamilton won the F1 2019 championship.\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608667,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 11,\n","    \"prompt_tokens\": 105,\n","    \"total_tokens\": 116\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Lewis Hamilton won the F1 2019 championship.\n"]}],"source":["#Recomended solution\n","context_user = [\n","    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n","    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n","    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Bettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n","    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n","    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n","]\n","\n","print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n","\n","However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."]},{"cell_type":"code","execution_count":14,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KELQx4tRDbztTH0Qdbldlf9sUfNi\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Driver: Lewis Hamilton\\nTeam: Mercedes\\nPoints: 413\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608728,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 13,\n","    \"prompt_tokens\": 77,\n","    \"total_tokens\": 90\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Driver: Lewis Hamilton\n","Team: Mercedes\n","Points: 413\n"]}],"source":["context_user = [\n","    {'role':'system', 'content':\"\"\"You are and expert in f1.\n","    You are going to answew the question of the user giving the name of the rider,\n","    the name of the team and the points of the champion, following the format:\n","    Drive:\n","    Team:\n","    Points: \"\"\"\n","    }\n","]\n","\n","print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"code","execution_count":15,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEMQrod6S9iBp2WZY9OfkfXkbpN7\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Driver: Fernando Alonso.\\nTeam: Renault.\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608790,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 9,\n","    \"prompt_tokens\": 77,\n","    \"total_tokens\": 86\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Driver: Fernando Alonso.\n","Team: Renault.\n"]}],"source":["context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are classifying .\n","\n","     Who won the 2010 f1 championship?\n","     Driver: Sebastian Bettel.\n","     Team: Red Bull Renault.\n","\n","     Who won the 2009 f1 championship?\n","     Driver: Jenson Button.\n","     Team: BrawnGP.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["### Few Shots for classification."]},{"cell_type":"code","execution_count":16,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KENPjvsQ8TpB7rJwglWAlbD6eFzW\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Sentiment: Neutral\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608851,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 4,\n","    \"prompt_tokens\": 134,\n","    \"total_tokens\": 138\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","Sentiment: Neutral\n"]}],"source":["context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n","\n","     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n","     Setiment: Positive\n","\n","     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n","     Sentiment: Negative.\n","\n","     I wouldn't know what to say, my son uses it, but he doesn't love it.\n","     Sentiment: Neutral\n","     \"\"\"}\n","]\n","print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"]},{"cell_type":"code","execution_count":17,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"id\": \"chatcmpl-9KEOO0tMizQcV9xaq2Q0YRT27qZW1\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"How can I help you?\",\n","        \"role\": \"assistant\",\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      },\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ],\n","  \"created\": 1714608912,\n","  \"model\": \"gpt-35-turbo\",\n","  \"object\": \"chat.completion\",\n","  \"system_fingerprint\": \"fp_2f57f81c11\",\n","  \"usage\": {\n","    \"completion_tokens\": 6,\n","    \"prompt_tokens\": 66,\n","    \"total_tokens\": 72\n","  },\n","  \"prompt_filter_results\": [\n","    {\n","      \"prompt_index\": 0,\n","      \"content_filter_results\": {\n","        \"hate\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"self_harm\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"sexual\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        },\n","        \"violence\": {\n","          \"filtered\": false,\n","          \"severity\": \"safe\"\n","        }\n","      }\n","    }\n","  ]\n","}\n","How can I help you?\n"]}],"source":["context_user=[\n","        {\"role\": \"system\", \"content\": \"You are an OrderBot in a fastfood restaurant.\"},\n","        {\"role\": \"user\", \"content\": \"I have only 10 dollars, what can I order?\"},\n","        {\"role\": \"assistant\", \"content\": \"We have the fast menu for 7 dollars.\"},\n","        {\"role\": \"user\", \"content\": \"Perfect! Give me one! \"}\n","]\n","print(return_OAIResponse(\"\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["## Content Generation\n","\n","In this section, we'll explore how to use LLMs to do content generation"]},{"cell_type":"code","execution_count":3,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","import semantic_kernel\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":4,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Introducing the 2019 Ford Explorer XLT in a stunning red color with only 32000 miles on the odometer. This vehicle is in excellent condition and is ready to take you on your next adventure. Priced at just $25000, this Explorer offers a spacious interior, powerful V6 engine, and a smooth ride. Don't miss out on this great deal! Contact us today to schedule a test drive.\n"]}],"source":["def mock_get_car() -> dict:\n","    return {\n","        \"make\": \"Ford\",\n","        \"model\": \"Explorer\",\n","        \"base\": \"XLT\",\n","        \"color\": \"red\",\n","        \"year\": 2019,\n","        \"condition\": \"good\",\n","        \"mileage\": 32000,\t\n","        \"price\": 25000\n","    }\n","\n","def get_car_description(car: dict) -> str:\n","    return f'{car[\"year\"]} {car[\"make\"]} {car[\"model\"]} {car[\"base\"]} {car[\"color\"]} with {car[\"mileage\"]} miles in {car[\"condition\"]} condition for ${car[\"price\"]}.'\n","\n","car = mock_get_car()\n","car_description = get_car_description(car)\n","\n","# Create a semantic kernel inline function\n","sales_desc_generation_template = \"Create a one paragraph sales description that includes the price for a {{input}}\"\n","template = common.render_template(sales_desc_generation_template, input=car_description)\n","\n","# Execute the SK function\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,template,max_tokens=500))"]},{"cell_type":"markdown","metadata":{},"source":["## Classification\n","\n","In this section, we'll explore how to use LLMs to do classification"]},{"cell_type":"code","execution_count":5,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["https://westus.api.cognitive.microsoft.com/\n"]}],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=\"2024-02-15-preview\",\n","        azure_endpoint=common.api_URI)\n","\n","print(common.api_URI)"]},{"cell_type":"code","execution_count":6,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Mammals:\n","- Dog\n","- Cat\n","- Elephant\n","- Dolphin\n","- Whale\n","\n","Fish/Reptiles:\n","- Shark\n","- Snake\n"]}],"source":["prompt_template = \"\"\"For the following list of animals:\n","\n","- Dog\n","- Cat\n","- Elephant\n","- Dolphin\n","- Shark\n","- Whale\n","- Snake\n","\n","Can you classify and list by animal type?\n","\"\"\"\n","\n","result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt_template)\n","\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["## Recommendations\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":7,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":8,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Joe's Stone Crab\n","Versailles\n","Hillstone\n","Casa Tua\n","Cecconi's\n","Yardbird Southern Table & Bar\n","\n","List two top restaurants:\n","{{input}}\n","Out in JSON format.\n","List two top restaurants:\n","Joe's Stone Crab\n","Versailles\n","Hillstone\n","Casa Tua\n","Cecconi's\n","Yardbird Southern Table & Bar\n","\n","Out in JSON format.\n","{\n","  \"restaurants\": [\n","    {\n","      \"name\": \"Joe's Stone Crab\",\n","      \"type\": \"Seafood\",\n","      \"location\": \"11 Washington Ave, Miami Beach, FL 33139\"\n","    },\n","    {\n","      \"name\": \"Versailles\",\n","      \"type\": \"Cuban\",\n","      \"location\": \"3555 SW 8th St, Miami, FL 33135\"\n","    },\n","    {\n","      \"name\": \"Hillstone\",\n","      \"type\": \"American\",\n","      \"location\": \"201 Miracle Mile, Coral Gables, FL 33134\"\n","    },\n","    {\n","      \"name\": \"Casa Tua\",\n","      \"type\": \"Italian\",\n","      \"location\": \"1700 James Ave, Miami Beach, FL 33139\"\n","    },\n","    {\n","      \"name\": \"Cecconi's\",\n","      \"type\": \"Italian\",\n","      \"location\": \"4385 Collins Ave, Miami Beach, FL 33140\"\n","\n"]}],"source":["def mock_get_restaurant_list(cityCode) -> list[str]:\n","    if (cityCode == \"MIA\"):\n","        return [\n","            \"Joe's Stone Crab\",\n","            \"Versailles\",\n","            \"Hillstone\",\n","            \"Casa Tua\",\t\n","            \"Cecconi's\",\n","            \"Yardbird Southern Table & Bar\",\n","        ]\n","    return []\n","\n","target_text=\"\"\n","for restaurant in mock_get_restaurant_list(\"MIA\"):\n","    target_text += f\"{restaurant}\\n\"\n","\n","print(target_text)\n","\n","recommendation_template = 'List two top restaurants:\\n{{input}}\\nOut in JSON format.'\n","print(recommendation_template)\n","rendered_template = common.render_template(recommendation_template, input=target_text)\n","print(rendered_template)\n","\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,rendered_template,max_tokens=200))"]},{"cell_type":"markdown","metadata":{},"source":["## Translation with Semantic Kernal\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":9,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: semantic_kernel in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (0.9.6b1)\n","Requirement already satisfied: aiohttp<4.0,>=3.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (3.9.3)\n","Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (0.7.1)\n","Requirement already satisfied: grpcio>=1.50.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (1.63.0)\n","Requirement already satisfied: jinja2<4.0.0,>=3.1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (3.1.3)\n","Requirement already satisfied: motor<4.0.0,>=3.3.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (3.4.0)\n","Requirement already satisfied: nest-asyncio<2.0.0,>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (1.6.0)\n","Requirement already satisfied: numpy>=1.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (1.26.4)\n","Requirement already satisfied: openai>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (1.9.0)\n","Requirement already satisfied: openapi_core<0.20,>=0.18 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (0.19.1)\n","Requirement already satisfied: prance<24.0.0.0,>=23.6.21.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (23.6.21.0)\n","Requirement already satisfied: pybars4<0.10.0,>=0.9.13 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (0.9.13)\n","Requirement already satisfied: pydantic<3,>=2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (2.7.1)\n","Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from semantic_kernel) (1.0.1)\n","Requirement already satisfied: regex<2024.0.0,>=2023.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (2023.10.3)\n","Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from semantic_kernel) (1.11.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (1.2.0)\n","Requirement already satisfied: attrs>=17.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (23.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (1.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.8->semantic_kernel) (1.9.3)\n","Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2<4.0.0,>=3.1.3->semantic_kernel) (2.1.3)\n","Requirement already satisfied: pymongo<5,>=4.5 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from motor<4.0.0,>=3.3.2->semantic_kernel) (4.7.1)\n","Requirement already satisfied: anyio<5,>=3.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai>=1.0->semantic_kernel) (1.8.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai>=1.0->semantic_kernel) (0.26.0)\n","Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from openai>=1.0->semantic_kernel) (1.3.0)\n","Requirement already satisfied: tqdm>4 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.65.0)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from openai>=1.0->semantic_kernel) (4.9.0)\n","Requirement already satisfied: isodate in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (0.6.1)\n","Requirement already satisfied: jsonschema<5.0.0,>=4.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (4.19.2)\n","Requirement already satisfied: jsonschema-path<0.4.0,>=0.3.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (0.3.2)\n","Requirement already satisfied: more-itertools in c:\\programdata\\anaconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (10.1.0)\n","Requirement already satisfied: openapi-schema-validator<0.7.0,>=0.6.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (0.6.2)\n","Requirement already satisfied: openapi-spec-validator<0.8.0,>=0.7.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (0.7.1)\n","Requirement already satisfied: parse in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (1.20.1)\n","Requirement already satisfied: werkzeug in c:\\programdata\\anaconda3\\lib\\site-packages (from openapi_core<0.20,>=0.18->semantic_kernel) (2.2.3)\n","Requirement already satisfied: chardet>=3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (4.0.0)\n","Requirement already satisfied: ruamel.yaml>=0.17.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (0.17.21)\n","Requirement already satisfied: requests>=2.25 in c:\\programdata\\anaconda3\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.31.0)\n","Requirement already satisfied: six~=1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (1.16.0)\n","Requirement already satisfied: packaging>=21.3 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (23.2)\n","Requirement already satisfied: PyMeta3>=0.5.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from pybars4<0.10.0,>=0.9.13->semantic_kernel) (0.5.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=2->semantic_kernel) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from pydantic<3,>=2->semantic_kernel) (2.18.2)\n","Requirement already satisfied: idna>=2.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.0->semantic_kernel) (3.4)\n","Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (2024.2.2)\n","Requirement already satisfied: httpcore==1.* in c:\\programdata\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (1.0.2)\n","Requirement already satisfied: h11<0.15,>=0.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.0->semantic_kernel) (0.14.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema<5.0.0,>=4.18.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.10.6)\n","Requirement already satisfied: PyYAML>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic_kernel) (6.0.1)\n","Requirement already satisfied: pathable<0.5.0,>=0.4.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from jsonschema-path<0.4.0,>=0.3.1->openapi_core<0.20,>=0.18->semantic_kernel) (0.4.3)\n","Requirement already satisfied: rfc3339-validator in c:\\programdata\\anaconda3\\lib\\site-packages (from openapi-schema-validator<0.7.0,>=0.6.0->openapi_core<0.20,>=0.18->semantic_kernel) (0.1.4)\n","Requirement already satisfied: lazy-object-proxy<2.0.0,>=1.7.1 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from openapi-spec-validator<0.8.0,>=0.7.1->openapi_core<0.20,>=0.18->semantic_kernel) (1.10.0)\n","Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\joluedem\\appdata\\roaming\\python\\python311\\site-packages (from pymongo<5,>=4.5->motor<4.0.0,>=3.3.2->semantic_kernel) (2.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.0.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.25->prance<24.0.0.0,>=23.6.21.0->semantic_kernel) (2.0.7)\n","Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.0->semantic_kernel) (0.4.6)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install semantic_kernel"]},{"cell_type":"code","execution_count":10,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Name: semantic-kernel\n","Version: 0.9.6b1\n","Summary: Semantic Kernel Python SDK\n","Home-page: \n","Author: Microsoft\n","Author-email: SK-Support@microsoft.com\n","License: \n","Location: C:\\Users\\joluedem\\AppData\\Roaming\\Python\\Python311\\site-packages\n","Requires: aiohttp, defusedxml, grpcio, jinja2, motor, nest-asyncio, numpy, openai, openapi_core, prance, pybars4, pydantic, python-dotenv, regex, scipy\n","Required-by: \n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip show semantic_kernel"]},{"cell_type":"code","execution_count":11,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-07-01-preview\n","https://westus.api.cognitive.microsoft.com/\n"]}],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)\n","\n","print(common.api_version)\n","print(common.api_URI)"]},{"cell_type":"code","execution_count":5,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import semantic_kernel as sk\n","\n","kernel = sk.Kernel()"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","\n","# Get a configured Semantic Kernel\n","# Note all other demos except this one use the OpenAI SDK\n","kernel = common.get_kernel()"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["languageCodes = {\n","    \"en\": \"English\",\n","    \"es\": \"Spanish\",\n","}\n","\n","def mock_get_extract_language(languageCode) -> str:\n","    if (languageCode == \"en\"):\n","        return '''Azure Container Apps is a fully managed environment that enables you to run microservices and containerized applications on a serverless platform. Common uses of Azure Container Apps include:\n","Deploying API endpoints\n","Hosting background processing applications\n","Handling event-driven processing\n","Running microservices'''\n","    return \"\"\n","\n","\n","source_language = languageCodes[\"en\"]  # English\n","target_language = languageCodes[\"es\"]  # Spanish\n","target_text = mock_get_extract_language(\"en\")\n","\n","translation_template = \"'Translate the text from {{$Source}} to {{$Target}}.\\nText:\\n\\n{{$input}}'\"\n","translationFunc = kernel.create_semantic_function(translation_template,max_tokens=100,temperature=0.3)\n","context = kernel.create_new_context()\n","context['Source'] = source_language\n","context['Target'] = target_language\n","context['input'] = target_text\n","\n","bot_answer = await translationFunc.invoke_async(context=context)\n","print(bot_answer)"]},{"cell_type":"markdown","metadata":{},"source":["## Sentiment\n","\n","In this section, we'll explore how to use LLMs to do sentiment analysis"]},{"cell_type":"code","execution_count":6,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":7,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Review: Mark S.: \"This smartphone has exceeded my expectations in ev, Score: 10\n","Review: Maya L.: \"I've been using this phone for a few weeks now, an, Score: 9\n","Review: David W.: \"What sets this smartphone apart is its seamless i, Score: 9\n","Review: Jennifer P.: \"The smartphone is decent overall. The camera t, Score: 5\n","Review: Ryan M.: \"This smartphone is a complete disappointment. The , Score: 1\n","Average sentiment score: 6.8\n"]}],"source":["import json\n","\n","reviews = [\n","    \"\"\"Mark S.: \\\"This smartphone has exceeded my expectations in every way. The camera quality is exceptional, capturing vivid details and colors. The battery life is impressive, easily lasting a full day with heavy usage. The sleek design and intuitive interface make it a pleasure to use. I'm a satisfied customer and would recommend it to anyone!\\\"\"\"\",\n","    \"\"\"Maya L.: \\\"I've been using this phone for a few weeks now, and it's a game-changer. The processing speed is fantastic, and I've experienced no lag even with multiple apps running. The display is vibrant, making videos and games look stunning. The fingerprint sensor is quick and accurate. Overall, a solid choice for anyone looking for a reliable and feature-packed smartphone.\\\"\"\"\",\n","    \"\"\"David W.: \\\"What sets this smartphone apart is its seamless integration with other devices. The ecosystem it creates is truly impressive, making my daily tasks more efficient. The build quality is robust, and the phone feels great in hand. The software updates have been regular, showing a commitment to keeping the device up to date. I'm very happy with my purchase.\\\"\"\"\",\n","    \"\"\"Jennifer P.: \\\"The smartphone is decent overall. The camera takes good photos, and the battery life is acceptable. However, I expected a bit more from the performance – there's a slight lag at times, especially when running resource-intensive apps. The design is standard, nothing particularly eye-catching. It's a reliable phone, but not a standout in the market.\\\"\"\"\",\n","    \"\"\"Ryan M.: \\\"This smartphone is a complete disappointment. The camera quality is subpar, producing grainy and washed-out photos. The battery drains rapidly, and even with minimal usage, it struggles to last half a day. The software is buggy, with frequent crashes and unresponsive touch screen. Save yourself the trouble and look elsewhere. This phone is not worth the money.\\\"\"\"\",    \n","]\n","\n","# Create a semantic kernel inline function\n","sentiment_template = \"\"\"From 1-10, 10 being a an excellent sentiment. What is the sentiment for: {{input}}?\n","\n","Output format: {\\\"sentiment\\\": 5}\n","\n","Output in JSON format only.\"\"\"\n","\n","# Execute the SK function\n","total_score = 0\n","for review in reviews:\n","    template = common.render_template(sentiment_template, input=review)\n","    data = common.Call_OpenAI(client,common.gpt_api_deployment,template)\n","    score = json.loads(data)['sentiment']\n","    print(f'Review: {review[0:60]}, Score: {score}')\n","    total_score += score\n","\n","print(\"Average sentiment score: {}\".format(total_score/len(reviews)))"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis\n","\n","In this section, we'll explore how to use LLMs to do analysis"]},{"cell_type":"code","execution_count":8,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-07-01-preview\n","gpt-35-turbo\n"]}],"source":["import common\n","\n","# Get a configured model\n","print(common.api_version)\n","print(common.gpt_api_deployment)\n","\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":9,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["def mock_get_contract(id: str) -> str:\n","    if id == \"LEASE_AGREEMENT\":\n","        return '''RESIDENTIAL LEASE AGREEMENT\n","RENT. The Tenant shall pay to Landlord the sum of $1,500 per month (hereinafter referred to as \"Rent\") for the duration of the Term of the Lease. The Rent shall be payable on or before every day of the month (hereinafter referred to as the \"Due Date\"), notwithstanding that the said date falls on a weekend or holiday.\n","A. Late Rent. If Rent is not paid within days of the Due Date, the Rent shall be considered past due, and a late fee of a $50 or 5% of the Rent past due shall be applied for every day Rent is late or O occurrence Rent is late.\n","B. Returned Checks. In the event that a check intended as payment for Rent is dishonored for whatever reason, the same shall be considered as Late Rent with the late fee being payable on the same.'''\n","    return \"\""]},{"cell_type":"code","execution_count":10,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# get a contract\n","contract = mock_get_contract(\"LEASE_AGREEMENT\")\n","\n","# print(contract)\n","# Create a semantic kernel inline function\n","analysis_template = \"\"\"System:\n","You are an agent that can help summarize and analyze contracts for risk. Be professional and courteous.\n","\n","User:\n","For the following text, summarize and list risks. \\n{{input}}\n","\n","Output format:\n","Summary: \n","\"\"\n","\n","Risks: \n","-||-\n","\n","\"\"\""]},{"cell_type":"code","execution_count":11,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["System:\n","You are an agent that can help summarize and analyze contracts for risk. Be professional and courteous.\n","\n","User:\n","For the following text, summarize and list risks. \n","RESIDENTIAL LEASE AGREEMENT\n","RENT. The Tenant shall pay to Landlord the sum of $1,500 per month (hereinafter referred to as \"Rent\") for the duration of the Term of the Lease. The Rent shall be payable on or before every day of the month (hereinafter referred to as the \"Due Date\"), notwithstanding that the said date falls on a weekend or holiday.\n","A. Late Rent. If Rent is not paid within days of the Due Date, the Rent shall be considered past due, and a late fee of a $50 or 5% of the Rent past due shall be applied for every day Rent is late or O occurrence Rent is late.\n","B. Returned Checks. In the event that a check intended as payment for Rent is dishonored for whatever reason, the same shall be considered as Late Rent with the late fee being payable on the same.\n","\n","Output format:\n","Summary: \n","\"\"\n","\n","Risks: \n","-||-\n","\n","Summary:\n","The residential lease agreement specifies the monthly rent of $1,500, the due date for payment, and the consequences of late payment or returned checks.\n","\n","Risks:\n","1. Late Rent: There is a risk of incurring late fees if the rent is not paid within the specified time frame.\n","2. Returned Checks: If a check for rent payment is dishonored, it will be considered late rent and may incur late fees.\n"]}],"source":["# Execute the function\n","template = common.render_template(analysis_template, input=contract)\n","print(template)\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,template,max_tokens=300))"]},{"cell_type":"markdown","metadata":{},"source":["## Scoring\n","\n","In this section, we'll explore how to use LLMs to do scoring"]},{"cell_type":"code","execution_count":12,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":13,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"score\":8, \"title\":\"La Canción de los Gatos\", \"explanation\": \"The song has complex vocabulary and descriptive language, making it challenging for an English speaker to learn.\"}\n","{\"score\":10, \"title\":\"Conquistando el Amor\", \"explanation\": \"The song contains complex vocabulary, poetic language, and metaphors, making it very challenging for an English speaker to learn.\"}\n"]}],"source":["songs = [\n","    ['La Canción de los Gatos', \"\"\"En el jardín, jugando van,\n","Pequeños gatos, con gran afán.\n","Pelos suaves, y orejas puntiagudas,\n","Saltan y juegan, ¡qué travesuras!\n","\n","¡Miau, miau, los gatos juegan así!\n","En la luz del sol, o bajo la luna, sí.\n","¡Miau, miau, saltan con destreza,\n","Los gatos son la pura belleza!\n","\n","Con bigotes finos, y ojos brillantes,\n","Exploran rincones, son tan elegantes.\n","Persiguen mariposas, atrapan ratones,\n","Los gatos son reyes de los callejones.\n","\n","¡Miau, miau, los gatos juegan así!\n","En la luz del sol, o bajo la luna, sí.\n","¡Miau, miau, saltan con destreza,\n","Los gatos son la pura belleza!\n","\n","Descansan en tejados, bajo el cielo estrellado,\n","Ronroneando suavemente, a veces hasta dormitando.\n","Cada gato, con su propia personalidad,\n","¡Son pequeños amigos llenos de vitalidad!\n","\n","¡Miau, miau, los gatos juegan así!\n","En la luz del sol, o bajo la luna, sí.\n","¡Miau, miau, saltan con destreza,\n","Los gatos son la pura belleza!\n","\n","Y así termina la canción de los gatos,\n","Con sus travesuras y sus saltos.\n","Gatitos felices, en su propio rincón,\n","¡Que la alegría de los gatos siga en tu corazón!\"\"\", \"Hard\"],\n","    ['Conquistando el Amor', \"\"\"En la penumbra de la noche, perdido en el laberinto,\n","Caminando entre susurros, buscando el amor instinto.\n","Ojos que brillan como estrellas, en la oscuridad se encuentran,\n","Corazones en batalla, donde las sombras se entrelazan.\n","\n","Conquistando el amor, en un juego sin final,\n","Donde las promesas se tejen, como hilos en el cristal.\n","Entre suspiros y secretos, dos almas se entrelazan,\n","En este duelo de pasiones, el amor se abalanza.\n","\n","En el campo de las emociones, donde la razón se desvanece,\n","Se libra la batalla, entre la dicha y la tristeza.\n","Susurros de seducción, en la danza de la pasión,\n","Labios que pronuncian versos, creando un lazo de unión.\n","\n","Bajo el cielo estrellado, donde los sueños se conjugan,\n","Se forja la alianza, que en el corazón se anida.\n","Palabras como flechas, atraviesan el silencio,\n","Conquistando el amor, en un eterno encuentro.\n","\n","Conquistando el amor, en un juego sin final,\n","Donde las promesas se tejen, como hilos en el cristal.\n","Entre suspiros y secretos, dos almas se entrelazan,\n","En este duelo de pasiones, el amor se abalanza.\n","\n","En el jardín de los sentimientos, donde florece la esperanza,\n","Se escribe la historia, de una conquista que avanza.\n","Manos que se buscan, en la penumbra del deseo,\n","Conquistando el amor, como un fuego que no teme.\n","\n","Bajo el manto de la Luna, sellando el pacto eterno,\n","Dos corazones en victoria, en este amor moderno.\n","Conquistando el amor, como héroes en la trama,\n","En este cuento sin final, donde el amor se proclama.\n","\"\"\", \"Easy\"]    \n","]\n","\n","for song in songs:\n","    \n","    prompt_template = \"\"\"You are an agent who can help determine how easy it would be for an English speaker to learn to sing a song in Spanish. Easy songs have straightforward vocabulary and grammar and avoid complex sentence structures, metaphors, poetic structures and language, and uncommon words. Songs with familiar or universal themes, such as love, emotions, or everyday activities, can be easier for learners to relate to and understand. It helps when the context of the song is relatable to the listener. \n","\n","    Rate the following song lyrics in Spanish from 1-10, with 10 being the hardest, for an English speaker to learn:\n","\n","    Song Title: \\\"\\\"\\\"\n","    {{title}}\n","    \\\"\\\"\\\"\n","\n","    Lyrics: \\\"\\\"\\\"\n","    {{input}}\n","    \\\"\\\"\\\"\n","\n","    \n","    Output format:\n","    { \\\"score\\\":-1, \\\"title\\\":\\\"\\\",\\\"explanation\\\": \\\"\\\"}\n","\n","    Provide an explanation in one sentence. Output in JSON format only.\n","    \"\"\"\n","\n","    rendered_template = common.render_template(prompt_template,title=song[0],input=song[1])    \n","    print(common.Call_OpenAI(client, common.gpt_api_deployment, rendered_template))"]},{"cell_type":"markdown","metadata":{},"source":["# Validation\n","\n","### Score how similar a baseline answer to an actual answer."]},{"cell_type":"code","execution_count":14,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(\n","        api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"markdown","metadata":{},"source":["### Create a Jinja2 template"]},{"cell_type":"code","execution_count":15,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["prompt_template = \"\"\"On a scale from 0-10 with 10 being a very good match, how close of a match is the Actual Response to the Baseline Response:\n","\n","Baseline response:\n","{{EXPECTED_ANSWER}}\n","\n","Actual Response:\n","{{ANSWER}}\n","\n","Output format:\n","{\n","\"score\":0,\n","\"reason\":\"\"\n","}\n","\n","Output in JSON format only.\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["### Check a good answer"]},{"cell_type":"code","execution_count":16,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["EXPECTED_ANSWER = \"The speed of light in a vacuum is approximately 299,792,458 meters per second (m/s). To convert this value to kilometers per second (km/s), we divide by 1,000 since there are 1,000 meters in a kilometer. Therefore, the speed of light in kilometers per second is approximately 299,792.458 km/s.\"\n","ANSWER = \"The speed of light is approximately 300,000 km/s.\"\n","prompt = rendered_template = common.render_template(prompt_template, EXPECTED_ANSWER=EXPECTED_ANSWER, ANSWER=ANSWER)"]},{"cell_type":"code","execution_count":17,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"score\": 5,\n","  \"reason\": \"The actual response is close in value to the baseline response, but it is not an exact match.\"\n","}\n"]}],"source":["result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt,temperature=0.0)\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["### Check a bad answer"]},{"cell_type":"code","execution_count":18,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["EXPECTED_ANSWER = \"The company offers paid sick leave, vacation, and paid medical insurance.\"\n","ANSWER = \"Some of the benefits are paid holidays and 401k matching.\"\n","prompt = rendered_template = common.render_template(prompt_template, EXPECTED_ANSWER=EXPECTED_ANSWER, ANSWER=ANSWER)"]},{"cell_type":"code","execution_count":19,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"score\": 3,\n","  \"reason\": \"The Actual Response mentions some benefits, but it does not specifically mention paid sick leave, vacation, and paid medical insurance as in the Baseline Response.\"\n","}\n"]}],"source":["result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt,temperature=0.0)\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["# Intent\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":20,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":21,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["intent_template = \"\"\"System:\n","You are a travel assistant that can help determine intent. An intent is an action from the list of Defined Intents. An action is defined as a place, location, name, time or date.\n","\n","Defined Intents:\n","GetItinerary\n","Reserve\n","CancelReservation\n","CheckReservation\n","GetReservation\n","GetWeather\n","Unknown\n","\n","User:\n","What is the intent and entities for the following request:\n","{{input}}\n","\n","Output format:\n","{\n","  \"intent\": \"intent\",\n","  \"entities\": [\"action\"]\n","}\n","\n","Do not provide explanations. Output in JSON format only.\"\"\""]},{"cell_type":"code","execution_count":22,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"intent\": \"Reserve\",\n","  \"entities\": [\"Friday's Restaurant\", \"7pm\", \"Friday\", \"2 people\"]\n","}\n"]}],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"I want to make a reservation for 2 people at 7pm on Friday at Friday's Restaurant.\")))"]},{"cell_type":"code","execution_count":23,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"intent\": \"GetItinerary\",\n","  \"entities\": []\n","}\n"]}],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"What is my upcoming travel itinerary?\")))"]},{"cell_type":"code","execution_count":24,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"intent\": \"GetWeather\",\n","  \"entities\": [\"London\"]\n","}\n"]}],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"What is the weather like in London?\")))"]},{"cell_type":"code","execution_count":25,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["{\n","  \"intent\": \"Unknown\",\n","  \"entities\": []\n","}\n"]}],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"What is the speed of light?\")))"]},{"cell_type":"markdown","metadata":{},"source":["# Function Calling\n","\n","The latest versions of gpt-35-turbo and gpt-4 are fine-tuned to work with functions and are able to both determine when and how a function should be called. \n","In this section, we'll explore how to work with LLMs and functions\n","\n","- Call the chat completions API with your functions and the user’s input\n","- Use the model’s response to call your API or function\n","- Call the chat completions API again, including the response from your function to get a final response"]},{"cell_type":"code","execution_count":30,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["https://westus.api.cognitive.microsoft.com/\n","2b6f1904286348cf8936389c0d1df7cc\n","gpt-35-turbo\n","ChatCompletion(id='chatcmpl-9KFVWxqqcFGHL3KSZAIhA8hXByhTR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"As of the latest information I have:\\n\\n- In San Francisco, the temperature is approximately 72°C. (This seems unusually high and is likely incorrect, please check a reliable local weather service for accurate information)\\n- In Tokyo, the temperature is around 10°C.\\n- In Paris, the temperature is about 22°C.\\n\\nPlease note that weather conditions can change rapidly, so for real-time data and to verify the unusually high temperature reported for San Francisco, it's best to consult a reliable weather forecasting service.\", role='assistant', function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1714613198, model='gpt-4', object='chat.completion', system_fingerprint='fp_1402c60a5a', usage=CompletionUsage(completion_tokens=103, prompt_tokens=169, total_tokens=272), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"]}],"source":["import os\n","from openai import AzureOpenAI\n","import json\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","print(os.getenv(\"AOAI_GPT35_DEPLOYMENT\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"), \n","  api_key=os.getenv(\"AOAI_APIKEY\"),  \n","  api_version=\"2024-03-01-preview\",\n","  #model=os.getenv(\"AOAI_GPT35_DEPLOYMENT\")\n",")\n","\n","# Example function hard coded to return the same weather\n","# In production, this could be your backend API or an external API\n","def get_current_weather(location, unit=\"fahrenheit\"):\n","    \"\"\"Get the current weather in a given location\"\"\"\n","    if \"tokyo\" in location.lower():\n","        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n","    elif \"san francisco\" in location.lower():\n","        return json.dumps({\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit})\n","    elif \"paris\" in location.lower():\n","        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n","    else:\n","        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n","\n","def run_conversation():\n","    # Step 1: send the conversation and available functions to the model\n","    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in San Francisco, Tokyo, and Paris?\"}]\n","    tools = [\n","        {\n","            \"type\": \"function\",\n","            \"function\": {\n","                \"name\": \"get_current_weather\",\n","                \"description\": \"Get the current weather in a given location\",\n","                \"parameters\": {\n","                    \"type\": \"object\",\n","                    \"properties\": {\n","                        \"location\": {\n","                            \"type\": \"string\",\n","                            \"description\": \"The city and state, e.g. San Francisco, CA\",\n","                        },\n","                        \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n","                    },\n","                    \"required\": [\"location\"],\n","                },\n","            },\n","        }\n","    ]\n","    response = client.chat.completions.create(\n","        model=os.getenv(\"AOAI_GPT35_DEPLOYMENT\"),\n","        messages=messages,\n","        tools=tools,\n","        tool_choice=\"auto\",  # auto is default, but we'll be explicit\n","    )\n","    response_message = response.choices[0].message\n","    tool_calls = response_message.tool_calls\n","    # Step 2: check if the model wanted to call a function\n","    if tool_calls:\n","        # Step 3: call the function\n","        # Note: the JSON response may not always be valid; be sure to handle errors\n","        available_functions = {\n","            \"get_current_weather\": get_current_weather,\n","        }  # only one function in this example, but you can have multiple\n","        messages.append(response_message)  # extend conversation with assistant's reply\n","        # Step 4: send the info for each function call and function response to the model\n","        for tool_call in tool_calls:\n","            function_name = tool_call.function.name\n","            function_to_call = available_functions[function_name]\n","            function_args = json.loads(tool_call.function.arguments)\n","            function_response = function_to_call(\n","                location=function_args.get(\"location\"),\n","                unit=function_args.get(\"unit\"),\n","            )\n","            messages.append(\n","                {\n","                    \"tool_call_id\": tool_call.id,\n","                    \"role\": \"tool\",\n","                    \"name\": function_name,\n","                    \"content\": function_response,\n","                }\n","            )  # extend conversation with function response\n","        second_response = client.chat.completions.create(\n","            model=os.getenv(\"AOAI_GPT4_DEPLOYMENT\"),\n","            messages=messages,\n","        )  # get a new response from the model where it can see the function response\n","        return second_response\n","print(run_conversation())"]},{"cell_type":"markdown","metadata":{},"source":["# 3.7 Embeddings & Vector DBs\n","\n","In this section, we'll explore Vector DBs, Embeddings and Chunking"]},{"cell_type":"code","execution_count":3,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["from PyPDF2 import PdfReader\n","# from sentence_transformers import SentenceTransformer\n","from dotenv import load_dotenv,dotenv_values\n","import json\n","from tenacity import retry, wait_random_exponential, stop_after_attempt"]},{"cell_type":"code","execution_count":4,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["G:\\OpenAI-DataPro\\notebooks\\assets\\azure-ai-services-openai.pdf\n"]}],"source":["FILE_PATH = \"G:\\\\OpenAI-DataPro\\\\notebooks\\\\assets\\\\azure-ai-services-openai.pdf\"\n","print(FILE_PATH)"]},{"cell_type":"code","execution_count":5,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# Read the PDF file and return the text\n","def get_pdf_data(file_path, num_pages = 1):\n","    reader = PdfReader(file_path)\n","    full_doc_text = \"\"\n","    pages = reader.pages\n","    num_pages = len(pages) \n","    \n","    try:\n","        for page in range(num_pages):\n","            current_page = reader.pages[page]\n","            text = current_page.extract_text()\n","            full_doc_text += text\n","    except:\n","        print(\"Error reading file\")\n","    finally:\n","        return full_doc_text"]},{"cell_type":"code","execution_count":6,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# Divide the text into chunks of chunk_length \n","# [ default is 500] characters\n","def get_chunks(fulltext:str,chunk_length =500) -> list:\n","    text = fulltext\n","\n","    chunks = []\n","    while len(text) > chunk_length:\n","        last_period_index = text[:chunk_length].rfind('.')\n","        if last_period_index == -1:\n","            last_period_index = chunk_length\n","        chunks.append(text[:last_period_index])\n","        text = text[last_period_index+1:]\n","    chunks.append(text)\n","\n","    return chunks"]},{"cell_type":"code","execution_count":7,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/plain":["'G:\\\\OpenAI-DataPro\\\\notebooks\\\\assets\\\\azure-ai-services-openai.pdf'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["filename = FILE_PATH\n","FILE_PATH.split('/')[-1]"]},{"cell_type":"code","execution_count":8,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"name":"stdout","output_type":"stream","text":["Full doc text length: 909339\n"]}],"source":["full_doc_text = get_pdf_data(filename)\n","print(f'Full doc text length: {len(full_doc_text)}')"]},{"cell_type":"code","execution_count":9,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/plain":["2162"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["Lines =get_chunks(full_doc_text,500)\n","len(Lines)"]},{"cell_type":"code","execution_count":10,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/plain":["list"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["type(Lines)"]},{"cell_type":"code","execution_count":11,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["from openai import AzureOpenAI\n","import os\n","\n","load_dotenv()  # make sure to have the .env file in the root directory of the project\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2024-02-15-preview\"\n",")\n","\n","model: str = os.getenv(\"AOAI_EMBEDDING_DEPLOYMENT\")"]},{"cell_type":"code","execution_count":12,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n","# Function to generate embeddings for title and content fields, also used for query embeddings\n","def generate_embeddings(text, model=model):\n","    return client.embeddings.create(input = [text], model=model).data[0].embedding"]},{"cell_type":"code","execution_count":13,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["counter = 0\n","input_data = []"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["%%time\n","for line in Lines:\n","    d = {}\n","    d['id'] = str(counter)\n","    d['line'] = line\n","    d['embedding'] = generate_embeddings(line)\n","    d['filename'] = FILE_PATH.split('/')[-1]\n","    counter = counter + 1\n","    input_data.append(d)"]},{"cell_type":"code","execution_count":15,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/plain":["549"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["counter"]},{"cell_type":"code","execution_count":16,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[{"data":{"text/plain":["1536"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["len(input_data[0]['embedding'])"]},{"cell_type":"code","execution_count":17,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# Output embeddings to docVectors.json file\n","with open(\"output/docVectors_azure.json\", \"w\") as f:\n","    json.dump(input_data, f)"]},{"cell_type":"markdown","metadata":{},"source":["# 3.8 SDKs and Orchestration\n","\n","In this section, we'll explore different SDKs (LangChan, Semantic Kernal) and orchestration methods such as Assistants APIs\n"]},{"cell_type":"markdown","metadata":{},"source":["### Math Tutor Assistant\n","\n","This sample demonstrates the following:\n","\n","- Showcases the foundational concepts of Assistants such as Threads, Messages, Runs, Tools, and lifecycle management.\n","\n","This sample shows users how to create an Azure OpenAI Assistant named \"Math Tutor\" using the Azure OpenAI API. The assistant is designed to function as a personal math tutor, capable of answering math questions through code interpretation. The script initiates a conversation with the assistant, guiding it through various mathematical queries and scenarios to showcase its capabilities.\n","\n","This sample provides developers with a clear demonstration of how to leverage the core concepts of the Assistants API into their projects, highlighting its simplicity and effectiveness in leveraging foundational concepts."]},{"cell_type":"code","execution_count":1,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import os\n","\n","from dotenv import load_dotenv\n","\n","#load_dotenv()  # make sure to have the .env file in the root directory of the project\n","\n","api_endpoint = os.getenv(\"AOAI_VISION_ENDPOINT\")\n","api_key = os.getenv(\"AOAI_VISION_APIKEY\")\n","api_version = \"2024-02-15-preview\"\n","api_deployment_name = os.getenv(\"AOAI_GPT4VISION_DEPLOYMENT\")\n","\n","should_cleanup: bool = False"]},{"cell_type":"markdown","metadata":{},"source":["## Run this Example\n","### Load the required libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import io\n","import time\n","from datetime import datetime\n","from typing import Iterable\n","\n","from openai import AzureOpenAI\n","from openai.types.beta.threads.message_content_image_file import MessageContentImageFile\n","from openai.types.beta.threads.message_content_text import MessageContentText\n","from openai.types.beta.threads.messages import MessageFile\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{},"source":["### Create an Azure OpenAI client"]},{"cell_type":"code","execution_count":4,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["client = AzureOpenAI(\n","api_key=os.getenv(\"AOAI_VISION_APIKEY\"), \n","api_version=os.getenv(\"AOAI_GPT4VISION_DEPLOYMENT\"),\n","azure_endpoint=os.getenv(\"AOAI_VISION_ENDPOINT\")\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Create an Assistant and a Thread"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["assistant = client.beta.assistants.create(\n","    name=\"Math Tutor\",\n","    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n","    tools=[{\"type\": \"code_interpreter\"}],\n","    model=api_deployment_name,\n",")\n","\n","thread = client.beta.threads.create()"]},{"cell_type":"markdown","metadata":{},"source":["### Format and display the Assistant Messages for text and images"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["def read_assistant_file(file_id:str):\n","    response_content = client.files.content(file_id)\n","    return response_content.read()\n","\n","def print_messages(messages: Iterable[MessageFile]) -> None:\n","    message_list = []\n","\n","    # Get all the messages till the last user message\n","    for message in messages:\n","        message_list.append(message)\n","        if message.role == \"user\":\n","            break\n","\n","    # Reverse the messages to show the last user message first\n","    message_list.reverse()\n","\n","    # Print the user or Assistant messages or images\n","    for message in message_list:\n","        for item in message.content:\n","            # Determine the content type\n","            if isinstance(item, MessageContentText):\n","                print(f\"{message.role}:\\n{item.text.value}\\n\")\n","                file_annotations = item.text.annotations\n","                if file_annotations:\n","                    for annotation in file_annotations:\n","                        file_id = annotation.file_path.file_id\n","                        content = read_assistant_file(file_id)\n","                        print(f\"Annotation Content:\\n{str(content)}\\n\")\n","            elif isinstance(item, MessageContentImageFile):\n","                # Retrieve image from file id                \n","                data_in_bytes = read_assistant_file(item.image_file.file_id)\n","                # Convert bytes to image\n","                readable_buffer = io.BytesIO(data_in_bytes)\n","                image = Image.open(readable_buffer)\n","                # Resize image to fit in terminal\n","                width, height = image.size\n","                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n","                # Display image\n","                image.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Process the user messages"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["def process_prompt(prompt: str) -> None:\n","    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n","    run = client.beta.threads.runs.create(\n","        thread_id=thread.id,\n","        assistant_id=assistant.id,\n","        instructions=\"Please address the user as Jane Doe. The user has a premium account. Be assertive, accurate, and polite. Ask if the user has further questions. \"\n","        + \"The current date and time is: \"\n","        + datetime.now().strftime(\"%x %X\")\n","        + \". \",\n","    )\n","    print(\"processing ...\")\n","    while True:\n","        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n","        if run.status == \"completed\":\n","            # Handle completed\n","            messages = client.beta.threads.messages.list(thread_id=thread.id)\n","            print_messages(messages)\n","            break\n","        if run.status == \"failed\":\n","            messages = client.beta.threads.messages.list(thread_id=thread.id)\n","            answer = messages.data[0].content[0].text.value\n","            print(f\"Failed User:\\n{prompt}\\nAssistant:\\n{answer}\\n\")\n","            # Handle failed\n","            break\n","        if run.status == \"expired\":\n","            # Handle expired\n","            print(run)\n","            break\n","        if run.status == \"cancelled\":\n","            # Handle cancelled\n","            print(run)\n","            break\n","        if run.status == \"requires_action\":\n","            # Handle function calling and continue processing\n","            pass\n","        else:\n","            time.sleep(5)"]},{"cell_type":"markdown","metadata":{},"source":["### Have a conversation with the Assistant"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["process_prompt(\"What is the linear equation when two (x,y) points are (1,1) and (5,10)?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["process_prompt(\"I need to solve the equation `3x + 11 = 14`. Can you help me?\")"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["process_prompt(\"\"\"x=r*cos(u)sin(v), y=r*sin(u)sin(v), r=2+sin(7*u+5*v) for 0<u<2π and 0<v<π.\n","Create a graph of the equation z=r*cos(v).\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["process_prompt(\"create a csv file with 10 customer names\")"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["if should_cleanup:\n","    client.beta.assistants.delete(assistant.id)\n","    client.beta.threads.delete(thread.id)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"polyglot_notebook":{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"name":"csharp"}]}}},"nbformat":4,"nbformat_minor":0}
