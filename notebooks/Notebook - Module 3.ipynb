{"cells":[{"cell_type":"markdown","metadata":{},"source":["![](../graphics/microsoftlogo.png)\n","\n","# Workshop: Unlocking AI Potential for the Data Professional - Azure OpenAI\n","\n","#### <i>A Microsoft Course from Microsoft Engineering and the FastTrack Team</i>\n","\n","<p style=\"border-bottom: 1px solid lightgrey;\"></p>\n","\n","<img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://raw.githubusercontent.com/microsoft/sqlworkshops/master/graphics/textbubble.png\"> <h2>Course Notebook: Module 3</h2>\n","\n","Welcome to this Microsoft solutions workshop on [*Unlocking AI Potential for the Data Professional with Azure OpenAI*](https://github.com/sqlserverworkshops/OpenAI-DataPro/tree/main). In this Notebook, you'll apply the concepts you learned in this Module.\n","\n","\n","Mastering the fundamentals and core concepts of OpenAI is indispensable for unlocking its full potential within Azure. Developers need a solid grasp of deploying Azure services like Azure OpenAI and Azure Cognitive Search, ensuring secure deployment aligned with responsible AI practices. This foundational knowledge guarantees that applications built on these services are not only functional but also ethically sound.\n","\n","Moreover, proficiency in interacting with OpenAI's Large Language Models (LLMs) via REST API is crucial for seamless integration into diverse applications. Developers must understand the underlying principles of OpenAI, including selecting the right model for specific tasks and discerning the advantages of different models in terms of token utilization and response precision. Understanding prompts, completions, chats and overall prompt engineering best practices is pivotal for crafting top-notch interactions with Azure OpenAI, whether it involves generating summaries, translations, or other functions.\n","\n","Furthermore, advanced concepts like smart load balancing for OpenAI endpoints and fine-tuning models are essential for maximizing performance and ensuring application resilience. As AI applications become increasingly intricate, grasping these core concepts not only empowers developers to construct more efficient solutions but also aids in mitigating potential risks associated with sophisticated language models. By simplifying the understanding of how these core concepts interconnect, our goal is to enable developers to build smarter applications using Azure OpenAI."]},{"cell_type":"markdown","metadata":{},"source":["# 3.2 Create Azure OpenAI Environment\n","\n","## Azure \n","\n","This notebook contains the script to create the necessary Azure environment to run the provided samples. The notebook uses [PowerShell](https://learn.microsoft.com/powershell/scripting/install/installing-powershell?view=powershell-7.3) and [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) to deploy all necessary Azure resources. Both tools are available on Windows, macOS and Linux environments.\n","\n","## Configuration\n","\n","This section performs two tasks:\n","\n","- Deployment of necessary Azure Services (Azure OpenAI, Azure Cognitive Search) to run samples\n","- Store all necessary service endpoints, service API keys, Azure OpenAI deployment names in a centralized file (../01_DemoEnvironment/conf/application.env). This file is used by all notebooks in this repo to connect and authenticate against the deployed Azure services.\n","\n","If you already have instances of Azure OpenAI and Azure Cognitive Search running you can rename the [configuration template](../conf/.env-sample) to `.env` and provide endpoint, API key and deployment names of a chat completion and an embedding model. We suggest to run the notebook to start a clean environment.\n","\n","### Visual Studio Code\n","\n","If you are running these steps below in Visual Studio Code make sure you switch your kernal to .NET Interactive so that it will run the PowerShell"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1:   Login to Azure; Get, Set subscription"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Check if you are already logged in\n","$loggedIn = az account show --query \"name\" -o tsv\n","\n","if ($null -ne $loggedIn) {\n","    Write-Host \"Already logged in as $loggedIn\"\n","} else {\n","    Write-Host \"Logging in...\"\n","    az login\n","}\n","# Retrieve default subscription id\n","$subscriptionId = (\n","    (\n","        az account list -o json `\n","            --query \"[?isDefault]\"\n","    ) | ConvertFrom-Json\n",").id\n","\n","# Set Subscription\n","az account set --subscription $subscriptionId\n","Write-Host \"Subscription set to $subscriptionId\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","If you're already logged in:\n","```\n","    Already logged in as xxxxx\n","    Subscription set to xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n","```\n","If you aren't logged in a browser window will pop-up which allows you to log in\n","```\n","    Logging in...\n","    Subscription set to xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2:   Define project unifier\n","\n","The project unifier is used to allow multiple deployments of services which have a need for a unique custom endpoint."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$random = Get-Random -Minimum 100 -Maximum 999\n","\n","Write-Host \"Unifier set to: $random\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Unifier set to: xxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3:   Create Resource Group\n","\n","In this sample all resources are deployed to `eastus`. Feel free to change to your preferred location."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$resourceGroup = \"OpenAI-DataPro-RG\"\n","$location = \"eastus\"\n","\n","az group create `\n","    --location $location `\n","    --resource-group $resourceGroup"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created resource group`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4:   Create Azure OpenAI instance\n","\n","An instance of Azure Cognitive Service with the kind `OpenAI` will be created. The `endpoint` and `API key` of the newly created instance are retrieved for later storage in the `application.env` file."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$csOpenAIName = \"aiservices$random\"\n","\n","az cognitiveservices account create `\n","    --name $csOpenAIName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --kind OpenAI `\n","    --sku S0 `\n","    --yes\n","\n","$csOpenAIEndpoint = ( `\n","    az cognitiveservices account show `\n","        --name $csOpenAIName `\n","        --resource-group $resourceGroup `\n","        --query properties.endpoint `\n","        --output tsv `\n",")\n","\n","$csOpenAIApiKey = (\n","    az cognitiveservices account keys list `\n","        --name $csOpenAIName `\n","        --resource-group $resourceGroup `\n","        --query key1 `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created Azure OpenAI instance`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5:   Deploy Azure OpenAI models\n","\n","Two LLM models are deployed to the newly created Azure Cognitive Service instance: \n","\n","- A chat completion model. In the sample we're deploying `gpt-35-turbo`. This can be replaced with other models providing a chat completion interface like `gpt-4`.\n","- A text embedding model. In the sample we're deploying `text-embedding-ada-002`. Any other text embedding model can be deployed as well."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Chat Completion Model GPT-3.5-turbo\n","$AOAI_GPT35_DEPLOYMENT = \"gpt-35-turbo\"\n","$modelName = \"gpt-35-turbo\"\n","$modelVersion = \"0301\"\n","$modelFormat = \"OpenAI\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT35_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Chat Completion Model GPT-4\n","$AOAI_GPT4_DEPLOYMENT = \"gpt-4\"\n","$modelName = \"gpt-4\"\n","$modelVersion = \"0613\"\n","$modelFormat = \"OpenAI\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT4_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Text Embedding Model\n","$AOAI_EMBEDDING_DEPLOYMENT = \"text-embedding-ada-002\"\n","$modelName = \"text-embedding-ada-002\"\n","$modelVersion = \"2\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_EMBEDDING_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# GPT-4 Vision Model - GPT-4 Turbo with Vision is the version of GPT-4 that accepts image inputs. It is available as the vision-preview model of gpt-4. The vision-preview model is available in only certain regions. For more information, see\n","# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#standard-deployment-model-availability\n","$AOAI_GPT4VISION_DEPLOYMENT = \"gpt-4-vision\"\n","$modelName = \"gpt-4\"\n","$modelVersion = \"vision-preview\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT4VISION_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly deployed models`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 6:   Create Azure Cognitive Search\n","\n","Azure Cognitive Search is deployed to use its [vector DB functionalities](https://learn.microsoft.com/en-us/azure/search/vector-search-overview). Just like with Azure OpenAI Cognitive Service, the `endpoint` and `API key` of the newly created instance are retrieved for later storage in the `application.env` file."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$csSearchName = \"aisearch$random\"\n","$csSearchSku = \"standard\"\n","\n","az search service create `\n","    --name $csSearchName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --sku $csSearchSku\n","\n","$csSearchEndpoint = \"https://$csSearchName.search.windows.net\"\n","\n","$csSearchApiKey = ( `\n","    az search admin-key show `\n","        --resource-group $resourceGroup `\n","        --service-name $csSearchName `\n","        --query primaryKey `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created cognitive search resource`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 7:   Create Azure Storage account\n","\n","Azure Storage is deployed to store data that can be used to generate indexes in Azure Cognitive Search."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$stgName = \"aistg$random\"\n","$stgSku = \"Standard_LRS\"\n","\n","az storage account create `\n","    --name $stgName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --sku $stgSku `\n","    --kind StorageV2 `\n","    --https-only true `\n","    --access-tier Hot\n","\n","$stgConnectionString = ( `\n","    az storage account show-connection-string `\n","        --name $stgName `\n","        --resource-group $resourceGroup `\n","        --query connectionString `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n","`JSON string describing the newly created storage account`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 8: Set environment variables & create application.env file"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Set environment variables\n","\n","$ENV:AOAI_ENDPOINT = $csOpenAIEndpoint\n","$ENV:AOAI_APIKEY = $csOpenAIApiKey\n","\n","#Azure Open AI GPT 3.5\n","$ENV:AOAI_GPT35_DEPLOYMENT = $AOAI_GPT35_DEPLOYMENT\n","\n","#Azure Open AI Embedding - text-embedding-ada-002\n","$ENV:AOAI_EMBEDDING_DEPLOYMENT = $AOAI_EMBEDDING_DEPLOYMENT\n","\n","#Azure Open AI GPT 4\n","$ENV:AOAI_GPT4_DEPLOYMENT = $AOAI_GPT4_DEPLOYMENT\n","\n","#Azure Open AI GPT 4 Vision\n","$ENV:AOAI_VISION_ENDPOINT = $csOpenAIEndpoint\n","$ENV:AOAI_VISION_APIKEY = $csOpenAIApiKey\n","$ENV:AOAI_GPT4VISION_DEPLOYMENT = $AOAI_GPT4VISION_DEPLOYMENT\n","\n","# Azure Search\n","$ENV:SEARCH_ENDPOINT = \"https://$csSearchEndpoint/\"\n","$ENV:SEARCH_APIKEY = $csSearchApiKey\n","\n","$ENV:STORAGE_CONNECTIONSTRING = $stgConnectionString\n","$ENV:ASSET_FOLDER = \"../../../../assets\"\n","\n","Write-Host \"Environment variables set!\"\n","\n","$configurationFile = \"../.env\"\n","\n","function Set-ConfigurationFileVariable($configurationFile, $variableName, $variableValue) {\n","    if (Select-String -Path $configurationFile -Pattern $variableName) {\n","        (Get-Content $configurationFile) | Foreach-Object {\n","            $_ -replace \"$variableName = .*\", \"$variableName=$variableValue\"\n","        } | Set-Content $configurationFile\n","    } else {\n","        Add-Content -Path $configurationFile -value \"$variableName=$variableValue\"\n","    }\n","}\n","\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_ENDPOINT\" $csOpenAIEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_APIKEY\" $csOpenAIApiKey\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT35_DEPLOYMENT\" $AOAI_GPT35_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_EMBEDDING_DEPLOYMENT\" $AOAI_EMBEDDING_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT4_DEPLOYMENT\" $AOAI_GPT4_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_VISION_ENDPOINT\" $csOpenAIEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_VISION_APIKEY\" $csOpenAIApiKey\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT4VISION_DEPLOYMENT\" $AOAI_GPT4VISION_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"SEARCH_ENDPOINT\" $csSearchEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"SEARCH_APIKEY\" $csSearchApiKey\n","Set-ConfigurationFileVariable $configurationFile \"STORAGE_CONNECTIONSTRING\" $stgConnectionString\n","Set-ConfigurationFileVariable $configurationFile \"ASSET_FOLDER\" \"../../../../assets\"\n","\n","\n","Write-Host \"Configuration file created at: $configurationFile\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Environment variables set!\n","Configuration file created at: xxxxxxxxxxxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 3.3 Basic Chat\n","\n","In this notebook, we'll explore basic prompt engineering techniques and recommendations that will help us elicit responses from Azure OpenAI Models\n","\n","### Visual Studio Code\n","\n","If you are running these steps below in Visual Studio Code make sure you switch your kernal to Python\n"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n","%pip install openai\n","%pip install panel "]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["%pip show openai"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import os\n","from openai import AzureOpenAI\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2024-02-15-preview\"\n",")\n","\n","chatgpt_model_name = os.getenv(\"AOAI_GPT4_DEPLOYMENT\")\n","print(chatgpt_model_name)"]},{"cell_type":"markdown","metadata":{},"source":["Chat models take a series of messages as input, and return a model-generated message as output. The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message)."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# A sample API call for chat completions looks as follows:\n","# Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message).\n","# For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions\n","import openai\n","try:\n","   \n","    response = client.chat.completions.create(\n","    model=chatgpt_model_name,\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n","        {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n","    ],\n","    temperature=0,\n","    max_tokens=800\n","    )\n","\n","    print(response.choices[0].message)\n","\n"," \n","except openai.APIError as e:\n","    # Handle API error here, e.g. retry or log\n","    print(f\"OpenAI API returned an API Error: {e}\")\n","\n","except openai.AuthenticationError as e:\n","    # Handle Authentication error here, e.g. invalid API key\n","    print(f\"OpenAI API returned an Authentication Error: {e}\")\n","\n","except openai.APIConnectionError as e:\n","    # Handle connection error here\n","    print(f\"Failed to connect to OpenAI API: {e}\")\n","\n","except openai.RateLimitError as e:\n","    # Handle rate limit error\n","    print(f\"OpenAI API request exceeded rate limit: {e}\")\n","\n","except openai.APITimeoutError as e:\n","    # Handle request timeout\n","    print(f\"Request timed out: {e}\")\n","    \n","except:\n","    # Handles all other exceptions\n","    print(\"An exception has occured.\")"]},{"cell_type":"markdown","metadata":{},"source":["## C# Example:  Setup Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["#r \"nuget: DotNetEnv, 2.5.0\"\n","#r \"nuget: System.Text.Json, 7.0.3\"\n","#r \"nuget: Newtonsoft.Json, 13.0.1\"\n","using DotNetEnv;\n","\n","using System.Net;\n","using System.Net.Http;\n","using System.Text.Json.Nodes;\n","using System.Text.Json;\n","\n","static string _configurationFile = @\"../.env\";\n","Env.Load(_configurationFile);\n","\n","string apiBase = Environment.GetEnvironmentVariable(\"AOAI_ENDPOINT\"); \n","string apiKey = Environment.GetEnvironmentVariable(\"AOAI_APIKEY\"); \n","string deploymentName = Environment.GetEnvironmentVariable(\"AOAI_GPT4_DEPLOYMENT\"); \n","string apiVersion = \"2023-07-01-preview\";"]},{"cell_type":"markdown","metadata":{},"source":["Expected output\n","```\n","Installed Packages\n","    DotNetEnv, 2.5.0\n","    Newtonsoft.Json, 13.0.1\n","    System.Text.Json, 7.0.3\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["Console.WriteLine(apiBase);\n","Console.WriteLine(apiKey);\n","Console.WriteLine(deploymentName);\n"]},{"cell_type":"markdown","metadata":{},"source":["## Create completions for chat messages with GPT models\n","\n","The code cell is using an instance of `HttpClient` to call the REST API of the deployed Azure OpenAI instance."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var requestPayload = new JsonObject\n","{\n","    { \"messages\", new JsonArray\n","        {\n","            new JsonObject\n","            {\n","                { \"role\", \"system\" },\n","                { \"content\", \"You are an AI assistance who You extract intention from provided text. You always answer with intention:\" }\n","                \n","            },\n","            new JsonObject\n","            {\n","                { \"role\", \"user\" },\n","                { \"content\", \"I'm not receiving calls on my Samsung Galaxy S22. Can you help?\" }\n","            }\n","        }\n","    },\n","    { \"max_tokens\", 200 },\n","    { \"temperature\", 0.7 },\n","    { \"frequency_penalty\", 0 },\n","    { \"presence_penalty\", 0 },\n","    { \"top_p\", 0.95 },\n","    { \"stop\", null }\n","};\n","\n","string payload = JsonSerializer.Serialize(requestPayload, new JsonSerializerOptions\n","{\n","    WriteIndented = true // Optional: to make the JSON string more readable\n","});\n","\n","        \n","string endpoint = $\"{apiBase}openai/deployments/{deploymentName}/chat/completions?api-version={apiVersion}\";\n","\n","using (HttpClient httpClient = new HttpClient())\n","{\n","    httpClient.BaseAddress = new Uri(endpoint);\n","    httpClient.DefaultRequestHeaders.Add(\"api-key\",apiKey);\n","    httpClient.DefaultRequestHeaders.Accept.Add(new System.Net.Http.Headers.MediaTypeWithQualityHeaderValue(\"application/json\"));\n","\n","    var stringContent = new StringContent(payload, Encoding.UTF8, \"application/json\");\n","\n","    var response = await httpClient.PostAsync(endpoint, stringContent);\n","\n","    if (response.IsSuccessStatusCode)\n","    {\n","        using (var responseStream = await response.Content.ReadAsStreamAsync())\n","        {\n","            // Parse the JSON response using JsonDocument\n","            using (var jsonDoc = await JsonDocument.ParseAsync(responseStream))\n","            {\n","                // Access the message content dynamically\n","                var root = jsonDoc.RootElement;\n","                var messageContent = root.GetProperty(\"choices\")[0].GetProperty(\"message\").GetProperty(\"content\").GetString();\n","\n","                // Output the message content\n","                Console.WriteLine(\"Output: \" + messageContent);\n","            }\n","        }\n","    }\n","    else\n","    {\n","        Console.WriteLine($\"Error: {response}\");\n","    }\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Output: Intention: Requesting technical assistance with phone call issue on Samsung Galaxy S22.\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 3.4 Tokenization\n","\n","In this notebook, we'll explore basic concepts behind tokenization, how to use the Microsoft.ML.Tokenizers library to tokenize text and get information about token counts\n","\n","https://github.com/Azure-Samples/openai-dotnet-samples/blob/main/tokenization.ipynb"]},{"cell_type":"markdown","metadata":{},"source":["### Install Microsoft.ML.Tokenizers"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["#r \"nuget:Microsoft.ML.Tokenizers\""]},{"cell_type":"markdown","metadata":{},"source":["Installed Packages\n"," - Microsoft.ML.Tokenizers, 0.21.1"]},{"cell_type":"markdown","metadata":{},"source":["### Add using statements"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["using Microsoft.ML.Tokenizers;"]},{"cell_type":"markdown","metadata":{},"source":["### Download and define vocab resources\n","\n","Download the following files and place them in the root directory. These vocabulary files are what are used to encode the text into tokens.\n","\n","- [GPT Vocabulary Files](https://huggingface.co/gpt2/tree/main)\n","    - vocab.json\n","    - merges.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var vocabFilePath = @\"../assets/vocab.json\";\n","var mergeFilePath = @\"../assets/merges.txt\";"]},{"cell_type":"markdown","metadata":{},"source":["### Initialize Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var tokenizer = new Tokenizer(new Bpe(vocabFilePath, mergeFilePath));"]},{"cell_type":"markdown","metadata":{},"source":["### Encode text into tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var input = \"the brown fox jumped over the lazy dog!\";\n","var tokenizerEncodedResult = tokenizer.Encode(input);\n","tokenizerEncodedResult"]},{"cell_type":"markdown","metadata":{},"source":["### Get token count"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["tokenizerEncodedResult.Tokens.Count()"]},{"cell_type":"markdown","metadata":{},"source":["# 3.5 Prompts & Completions\n","\n","In this section, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs. The techniques in this section will teach you strategies for increasing the accuracy and grounding of responses you generate with a Large Language Model (LLM)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install openai\n","%pip install panel \n","%pip install semantic_kernel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from openai import AzureOpenAI\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2024-02-15-preview\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = client.chat.completions.create(\n","    model=\"gpt-35-turbo\", # model = \"deployment_name\".\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"Assistant is a large language model trained by OpenAI.\"},\n","        {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n","    ]\n",")\n","\n","#print(response)\n","print(response.model_dump_json(indent=2))\n","print(response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["# Formating the answer with Few Shot Samples.\n","\n","To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n","\n","Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n","\n","Depending on the number of examples given, this technique can be referred to as:\n","* Zero-Shot - which refers to providing no examples\n","* One-Shot.\n","* Few-Shots - The term few-shot refers to providing a few of examples to help the model learn what it needs to do\n","\n","With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Functio to call the model.\n","def return_OAIResponse(user_message, context):\n","\n","#As we can see, we’re adding the user’s question at the end of the prompt with the user role, so the model understands that this is a user request and not an instruction on how it should work.\n","    newcontext = context.copy()\n","    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n","\n","    # print(newcontext)\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-35-turbo\", # model = \"deployment_name\".\n","        messages=newcontext,\n","        temperature=0,\n","        max_tokens=800\n","    )\n","\n","    # print(response)\n","    print(response.model_dump_json(indent=2))\n","\n","    return (response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#zero-shot\n","context_user = [\n","    {'role':'system', 'content':'You are an expert in F1.'}\n","]\n","print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#one-shot\n","context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in F1.\n","\n","     Who won the 2000 f1 championship?\n","     Driver: Michael Schumacher.\n","     Team: Ferrari.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Few shots\n","context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in F1.\n","\n","     Who won the 2010 f1 championship?\n","     Driver: Sebastian Bettel.\n","     Team: Red Bull Renault.\n","\n","     Who won the 2009 f1 championship?\n","     Driver: Jenson Button.\n","     Team: BrawnGP.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n","\n","However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n","\n","By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Recomended solution\n","context_user = [\n","    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n","    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n","    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Bettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n","    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n","    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n","]\n","\n","print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n","\n","However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user = [\n","    {'role':'system', 'content':\"\"\"You are and expert in f1.\n","    You are going to answew the question of the user giving the name of the rider,\n","    the name of the team and the points of the champion, following the format:\n","    Drive:\n","    Team:\n","    Points: \"\"\"\n","    }\n","]\n","\n","print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are classifying .\n","\n","     Who won the 2010 f1 championship?\n","     Driver: Sebastian Bettel.\n","     Team: Red Bull Renault.\n","\n","     Who won the 2009 f1 championship?\n","     Driver: Jenson Button.\n","     Team: BrawnGP.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["### Few Shots for classification."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n","\n","     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n","     Setiment: Positive\n","\n","     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n","     Sentiment: Negative.\n","\n","     I wouldn't know what to say, my son uses it, but he doesn't love it.\n","     Sentiment: Neutral\n","     \"\"\"}\n","]\n","print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user=[\n","        {\"role\": \"system\", \"content\": \"You are an OrderBot in a fastfood restaurant.\"},\n","        {\"role\": \"user\", \"content\": \"I have only 10 dollars, what can I order?\"},\n","        {\"role\": \"assistant\", \"content\": \"We have the fast menu for 7 dollars.\"},\n","        {\"role\": \"user\", \"content\": \"Perfect! Give me one! \"}\n","]\n","print(return_OAIResponse(\"\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["## Content Generation\n","\n","In this section, we'll explore how to use LLMs to do content generation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mock_get_car() -> dict:\n","    return {\n","        \"make\": \"Ford\",\n","        \"model\": \"Explorer\",\n","        \"base\": \"XLT\",\n","        \"color\": \"red\",\n","        \"year\": 2019,\n","        \"condition\": \"good\",\n","        \"mileage\": 32000,\t\n","        \"price\": 25000\n","    }\n","\n","def get_car_description(car: dict) -> str:\n","    return f'{car[\"year\"]} {car[\"make\"]} {car[\"model\"]} {car[\"base\"]} {car[\"color\"]} with {car[\"mileage\"]} miles in {car[\"condition\"]} condition for ${car[\"price\"]}.'\n","\n","car = mock_get_car()\n","car_description = get_car_description(car)\n","\n","# Create a semantic kernel inline function\n","sales_desc_generation_template = \"Create a one paragraph sales description that includes the price for a {{input}}\"\n","template = common.render_template(sales_desc_generation_template, input=car_description)\n","\n","# Execute the SK function\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,template,max_tokens=500))"]},{"cell_type":"markdown","metadata":{},"source":["## Classification\n","\n","In this section, we'll explore how to use LLMs to do classification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=\"2024-02-15-preview\",\n","        azure_endpoint=common.api_URI)\n","\n","print(common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt_template = \"\"\"For the following list of animals:\n","\n","- Dog\n","- Cat\n","- Elephant\n","- Dolphin\n","- Shark\n","- Whale\n","- Snake\n","\n","Can you classify and list by animal type?\n","\"\"\"\n","\n","result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt_template)\n","\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["## Recommendations\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mock_get_restaurant_list(cityCode) -> list[str]:\n","    if (cityCode == \"MIA\"):\n","        return [\n","            \"Joe's Stone Crab\",\n","            \"Versailles\",\n","            \"Hillstone\",\n","            \"Casa Tua\",\t\n","            \"Cecconi's\",\n","            \"Yardbird Southern Table & Bar\",\n","        ]\n","    return []\n","\n","target_text=\"\"\n","for restaurant in mock_get_restaurant_list(\"MIA\"):\n","    target_text += f\"{restaurant}\\n\"\n","\n","print(target_text)\n","\n","recommendation_template = 'List two top restaurants:\\n{{input}}\\nOut in JSON format.'\n","print(recommendation_template)\n","rendered_template = common.render_template(recommendation_template, input=target_text)\n","print(rendered_template)\n","\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,rendered_template,max_tokens=200))"]},{"cell_type":"markdown","metadata":{},"source":["## Translation with Semantic Kernal\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install semantic_kernel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip show semantic_kernel"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)\n","\n","print(common.api_version)\n","print(common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import semantic_kernel as sk\n","\n","kernel = sk.Kernel()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured Semantic Kernel\n","# Note all other demos except this one use the OpenAI SDK\n","kernel = common.get_kernel()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["languageCodes = {\n","    \"en\": \"English\",\n","    \"es\": \"Spanish\",\n","}\n","\n","def mock_get_extract_language(languageCode) -> str:\n","    if (languageCode == \"en\"):\n","        return '''Azure Container Apps is a fully managed environment that enables you to run microservices and containerized applications on a serverless platform. Common uses of Azure Container Apps include:\n","Deploying API endpoints\n","Hosting background processing applications\n","Handling event-driven processing\n","Running microservices'''\n","    return \"\"\n","\n","\n","source_language = languageCodes[\"en\"]  # English\n","target_language = languageCodes[\"es\"]  # Spanish\n","target_text = mock_get_extract_language(\"en\")\n","\n","translation_template = \"'Translate the text from {{$Source}} to {{$Target}}.\\nText:\\n\\n{{$input}}'\"\n","translationFunc = kernel.create_semantic_function(translation_template,max_tokens=100,temperature=0.3)\n","context = kernel.create_new_context()\n","context['Source'] = source_language\n","context['Target'] = target_language\n","context['input'] = target_text\n","\n","bot_answer = await translationFunc.invoke_async(context=context)\n","print(bot_answer)"]},{"cell_type":"markdown","metadata":{},"source":["## Sentiment\n","\n","In this section, we'll explore how to use LLMs to do sentiment analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json\n","\n","reviews = [\n","    \"\"\"Mark S.: \\\"This smartphone has exceeded my expectations in every way. The camera quality is exceptional, capturing vivid details and colors. The battery life is impressive, easily lasting a full day with heavy usage. The sleek design and intuitive interface make it a pleasure to use. I'm a satisfied customer and would recommend it to anyone!\\\"\"\"\",\n","    \"\"\"Maya L.: \\\"I've been using this phone for a few weeks now, and it's a game-changer. The processing speed is fantastic, and I've experienced no lag even with multiple apps running. The display is vibrant, making videos and games look stunning. The fingerprint sensor is quick and accurate. Overall, a solid choice for anyone looking for a reliable and feature-packed smartphone.\\\"\"\"\",\n","    \"\"\"David W.: \\\"What sets this smartphone apart is its seamless integration with other devices. The ecosystem it creates is truly impressive, making my daily tasks more efficient. The build quality is robust, and the phone feels great in hand. The software updates have been regular, showing a commitment to keeping the device up to date. I'm very happy with my purchase.\\\"\"\"\",\n","    \"\"\"Jennifer P.: \\\"The smartphone is decent overall. The camera takes good photos, and the battery life is acceptable. However, I expected a bit more from the performance – there's a slight lag at times, especially when running resource-intensive apps. The design is standard, nothing particularly eye-catching. It's a reliable phone, but not a standout in the market.\\\"\"\"\",\n","    \"\"\"Ryan M.: \\\"This smartphone is a complete disappointment. The camera quality is subpar, producing grainy and washed-out photos. The battery drains rapidly, and even with minimal usage, it struggles to last half a day. The software is buggy, with frequent crashes and unresponsive touch screen. Save yourself the trouble and look elsewhere. This phone is not worth the money.\\\"\"\"\",    \n","]\n","\n","# Create a semantic kernel inline function\n","sentiment_template = \"\"\"From 1-10, 10 being a an excellent sentiment. What is the sentiment for: {{input}}?\n","\n","Output format: {\\\"sentiment\\\": 5}\n","\n","Output in JSON format only.\"\"\"\n","\n","# Execute the SK function\n","total_score = 0\n","for review in reviews:\n","    template = common.render_template(sentiment_template, input=review)\n","    data = common.Call_OpenAI(client,common.gpt_api_deployment,template)\n","    score = json.loads(data)['sentiment']\n","    print(f'Review: {review[0:60]}, Score: {score}')\n","    total_score += score\n","\n","print(\"Average sentiment score: {}\".format(total_score/len(reviews)))"]},{"cell_type":"markdown","metadata":{},"source":["## Analysis\n","\n","In this section, we'll explore how to use LLMs to do analysis"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","print(common.api_version)\n","print(common.gpt_api_deployment)\n","\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mock_get_contract(id: str) -> str:\n","    if id == \"LEASE_AGREEMENT\":\n","        return '''RESIDENTIAL LEASE AGREEMENT\n","RENT. The Tenant shall pay to Landlord the sum of $1,500 per month (hereinafter referred to as \"Rent\") for the duration of the Term of the Lease. The Rent shall be payable on or before every day of the month (hereinafter referred to as the \"Due Date\"), notwithstanding that the said date falls on a weekend or holiday.\n","A. Late Rent. If Rent is not paid within days of the Due Date, the Rent shall be considered past due, and a late fee of a $50 or 5% of the Rent past due shall be applied for every day Rent is late or O occurrence Rent is late.\n","B. Returned Checks. In the event that a check intended as payment for Rent is dishonored for whatever reason, the same shall be considered as Late Rent with the late fee being payable on the same.'''\n","    return \"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get a contract\n","contract = mock_get_contract(\"LEASE_AGREEMENT\")\n","\n","# print(contract)\n","# Create a semantic kernel inline function\n","analysis_template = \"\"\"System:\n","You are an agent that can help summarize and analyze contracts for risk. Be professional and courteous.\n","\n","User:\n","For the following text, summarize and list risks. \\n{{input}}\n","\n","Output format:\n","Summary: \n","\"\"\n","\n","Risks: \n","-||-\n","\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Execute the function\n","template = common.render_template(analysis_template, input=contract)\n","print(template)\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,template,max_tokens=300))"]},{"cell_type":"markdown","metadata":{},"source":["## Scoring\n","\n","In this section, we'll explore how to use LLMs to do scoring"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["songs = [\n","    ['La Canción de los Gatos', \"\"\"En el jardín, jugando van,\n","Pequeños gatos, con gran afán.\n","Pelos suaves, y orejas puntiagudas,\n","Saltan y juegan, ¡qué travesuras!\n","\n","¡Miau, miau, los gatos juegan así!\n","En la luz del sol, o bajo la luna, sí.\n","¡Miau, miau, saltan con destreza,\n","Los gatos son la pura belleza!\n","\n","Con bigotes finos, y ojos brillantes,\n","Exploran rincones, son tan elegantes.\n","Persiguen mariposas, atrapan ratones,\n","Los gatos son reyes de los callejones.\n","\n","¡Miau, miau, los gatos juegan así!\n","En la luz del sol, o bajo la luna, sí.\n","¡Miau, miau, saltan con destreza,\n","Los gatos son la pura belleza!\n","\n","Descansan en tejados, bajo el cielo estrellado,\n","Ronroneando suavemente, a veces hasta dormitando.\n","Cada gato, con su propia personalidad,\n","¡Son pequeños amigos llenos de vitalidad!\n","\n","¡Miau, miau, los gatos juegan así!\n","En la luz del sol, o bajo la luna, sí.\n","¡Miau, miau, saltan con destreza,\n","Los gatos son la pura belleza!\n","\n","Y así termina la canción de los gatos,\n","Con sus travesuras y sus saltos.\n","Gatitos felices, en su propio rincón,\n","¡Que la alegría de los gatos siga en tu corazón!\"\"\", \"Hard\"],\n","    ['Conquistando el Amor', \"\"\"En la penumbra de la noche, perdido en el laberinto,\n","Caminando entre susurros, buscando el amor instinto.\n","Ojos que brillan como estrellas, en la oscuridad se encuentran,\n","Corazones en batalla, donde las sombras se entrelazan.\n","\n","Conquistando el amor, en un juego sin final,\n","Donde las promesas se tejen, como hilos en el cristal.\n","Entre suspiros y secretos, dos almas se entrelazan,\n","En este duelo de pasiones, el amor se abalanza.\n","\n","En el campo de las emociones, donde la razón se desvanece,\n","Se libra la batalla, entre la dicha y la tristeza.\n","Susurros de seducción, en la danza de la pasión,\n","Labios que pronuncian versos, creando un lazo de unión.\n","\n","Bajo el cielo estrellado, donde los sueños se conjugan,\n","Se forja la alianza, que en el corazón se anida.\n","Palabras como flechas, atraviesan el silencio,\n","Conquistando el amor, en un eterno encuentro.\n","\n","Conquistando el amor, en un juego sin final,\n","Donde las promesas se tejen, como hilos en el cristal.\n","Entre suspiros y secretos, dos almas se entrelazan,\n","En este duelo de pasiones, el amor se abalanza.\n","\n","En el jardín de los sentimientos, donde florece la esperanza,\n","Se escribe la historia, de una conquista que avanza.\n","Manos que se buscan, en la penumbra del deseo,\n","Conquistando el amor, como un fuego que no teme.\n","\n","Bajo el manto de la Luna, sellando el pacto eterno,\n","Dos corazones en victoria, en este amor moderno.\n","Conquistando el amor, como héroes en la trama,\n","En este cuento sin final, donde el amor se proclama.\n","\"\"\", \"Easy\"]    \n","]\n","\n","for song in songs:\n","    \n","    prompt_template = \"\"\"You are an agent who can help determine how easy it would be for an English speaker to learn to sing a song in Spanish. Easy songs have straightforward vocabulary and grammar and avoid complex sentence structures, metaphors, poetic structures and language, and uncommon words. Songs with familiar or universal themes, such as love, emotions, or everyday activities, can be easier for learners to relate to and understand. It helps when the context of the song is relatable to the listener. \n","\n","    Rate the following song lyrics in Spanish from 1-10, with 10 being the hardest, for an English speaker to learn:\n","\n","    Song Title: \\\"\\\"\\\"\n","    {{title}}\n","    \\\"\\\"\\\"\n","\n","    Lyrics: \\\"\\\"\\\"\n","    {{input}}\n","    \\\"\\\"\\\"\n","\n","    \n","    Output format:\n","    { \\\"score\\\":-1, \\\"title\\\":\\\"\\\",\\\"explanation\\\": \\\"\\\"}\n","\n","    Provide an explanation in one sentence. Output in JSON format only.\n","    \"\"\"\n","\n","    rendered_template = common.render_template(prompt_template,title=song[0],input=song[1])    \n","    print(common.Call_OpenAI(client, common.gpt_api_deployment, rendered_template))"]},{"cell_type":"markdown","metadata":{},"source":["# Validation\n","\n","### Score how similar a baseline answer to an actual answer."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(\n","        api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"markdown","metadata":{},"source":["### Create a Jinja2 template"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt_template = \"\"\"On a scale from 0-10 with 10 being a very good match, how close of a match is the Actual Response to the Baseline Response:\n","\n","Baseline response:\n","{{EXPECTED_ANSWER}}\n","\n","Actual Response:\n","{{ANSWER}}\n","\n","Output format:\n","{\n","\"score\":0,\n","\"reason\":\"\"\n","}\n","\n","Output in JSON format only.\"\"\""]},{"cell_type":"markdown","metadata":{},"source":["### Check a good answer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EXPECTED_ANSWER = \"The speed of light in a vacuum is approximately 299,792,458 meters per second (m/s). To convert this value to kilometers per second (km/s), we divide by 1,000 since there are 1,000 meters in a kilometer. Therefore, the speed of light in kilometers per second is approximately 299,792.458 km/s.\"\n","ANSWER = \"The speed of light is approximately 300,000 km/s.\"\n","prompt = rendered_template = common.render_template(prompt_template, EXPECTED_ANSWER=EXPECTED_ANSWER, ANSWER=ANSWER)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt,temperature=0.0)\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["### Check a bad answer"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["EXPECTED_ANSWER = \"The company offers paid sick leave, vacation, and paid medical insurance.\"\n","ANSWER = \"Some of the benefits are paid holidays and 401k matching.\"\n","prompt = rendered_template = common.render_template(prompt_template, EXPECTED_ANSWER=EXPECTED_ANSWER, ANSWER=ANSWER)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt,temperature=0.0)\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["# Intent\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["intent_template = \"\"\"System:\n","You are a travel assistant that can help determine intent. An intent is an action from the list of Defined Intents. An action is defined as a place, location, name, time or date.\n","\n","Defined Intents:\n","GetItinerary\n","Reserve\n","CancelReservation\n","CheckReservation\n","GetReservation\n","GetWeather\n","Unknown\n","\n","User:\n","What is the intent and entities for the following request:\n","{{input}}\n","\n","Output format:\n","{\n","  \"intent\": \"intent\",\n","  \"entities\": [\"action\"]\n","}\n","\n","Do not provide explanations. Output in JSON format only.\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"I want to make a reservation for 2 people at 7pm on Friday at Friday's Restaurant.\")))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"What is my upcoming travel itinerary?\")))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"What is the weather like in London?\")))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(common.Call_OpenAI(client,common.gpt_api_deployment,common.render_template(intent_template,input=\"What is the speed of light?\")))"]},{"cell_type":"markdown","metadata":{},"source":["# 3.7 Embeddings & Vector DBs\n","\n","In this section, we'll explore Vector DBs, Embeddings and Chunking"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from PyPDF2 import PdfReader\n","# from sentence_transformers import SentenceTransformer\n","from dotenv import load_dotenv,dotenv_values\n","import json\n","from tenacity import retry, wait_random_exponential, stop_after_attempt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["FILE_PATH = \"C:/Git/AzureOpenAI/OpenAI-DataPro/notebooks/assets/azure-ai-services-openai.pdf\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Read the PDF file and return the text\n","def get_pdf_data(file_path, num_pages = 1):\n","    reader = PdfReader(file_path)\n","    full_doc_text = \"\"\n","    pages = reader.pages\n","    num_pages = len(pages) \n","    \n","    try:\n","        for page in range(num_pages):\n","            current_page = reader.pages[page]\n","            text = current_page.extract_text()\n","            full_doc_text += text\n","    except:\n","        print(\"Error reading file\")\n","    finally:\n","        return full_doc_text"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Divide the text into chunks of chunk_length \n","# [ default is 500] characters\n","def get_chunks(fulltext:str,chunk_length =500) -> list:\n","    text = fulltext\n","\n","    chunks = []\n","    while len(text) > chunk_length:\n","        last_period_index = text[:chunk_length].rfind('.')\n","        if last_period_index == -1:\n","            last_period_index = chunk_length\n","        chunks.append(text[:last_period_index])\n","        text = text[last_period_index+1:]\n","    chunks.append(text)\n","\n","    return chunks"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["filename = FILE_PATH\n","FILE_PATH.split('/')[-1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["full_doc_text = get_pdf_data(filename)\n","print(f'Full doc text length: {len(full_doc_text)}')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Lines =get_chunks(full_doc_text,500)\n","len(Lines)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["type(Lines)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from openai import AzureOpenAI\n","import os\n","\n","load_dotenv()  # make sure to have the .env file in the root directory of the project\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2024-02-15-preview\"\n",")\n","\n","model: str = os.getenv(\"AOAI_EMBEDDING_DEPLOYMENT\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n","# Function to generate embeddings for title and content fields, also used for query embeddings\n","def generate_embeddings(text, model=model):\n","    return client.embeddings.create(input = [text], model=model).data[0].embedding"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["counter = 0\n","input_data = []"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","for line in Lines:\n","    d = {}\n","    d['id'] = str(counter)\n","    d['line'] = line\n","    d['embedding'] = generate_embeddings(line)\n","    d['filename'] = FILE_PATH.split('/')[-1]\n","    counter = counter + 1\n","    input_data.append(d)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["counter"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(input_data[0]['embedding'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Output embeddings to docVectors.json file\n","with open(\"output/docVectors_azure.json\", \"w\") as f:\n","    json.dump(input_data, f)"]},{"cell_type":"markdown","metadata":{},"source":["# 3.8 SDKs and Orchestration\n","\n","In this section, we'll explore different SDKs (LangChan, Semantic Kernal) and orchestration methods such as Assistants APIs\n"]},{"cell_type":"markdown","metadata":{},"source":["### Math Tutor Assistant\n","\n","This sample demonstrates the following:\n","\n","- Showcases the foundational concepts of Assistants such as Threads, Messages, Runs, Tools, and lifecycle management.\n","\n","This sample shows users how to create an Azure OpenAI Assistant named \"Math Tutor\" using the Azure OpenAI API. The assistant is designed to function as a personal math tutor, capable of answering math questions through code interpretation. The script initiates a conversation with the assistant, guiding it through various mathematical queries and scenarios to showcase its capabilities.\n","\n","This sample provides developers with a clear demonstration of how to leverage the core concepts of the Assistants API into their projects, highlighting its simplicity and effectiveness in leveraging foundational concepts."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","\n","from dotenv import load_dotenv\n","\n","load_dotenv()  # make sure to have the .env file in the root directory of the project\n","\n","api_endpoint = os.getenv(\"AZURE_OPENAI_SWEDEN_ENDPOINT\")\n","api_key = os.getenv(\"AZURE_OPENAI_SWEDEN_KEY\")\n","api_version = os.getenv(\"AZURE_OPENAI_SWEDEN_API_VERSION\")\n","api_deployment_name = os.getenv(\"AZURE_OPENAI_SWEDEN_GPT_DEPLOYMENT\")\n","\n","should_cleanup: bool = False"]},{"cell_type":"markdown","metadata":{},"source":["## Run this Example\n","### Load the required libraries"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import io\n","import time\n","from datetime import datetime\n","from typing import Iterable\n","\n","from openai import AzureOpenAI\n","from openai.types.beta.threads.message_content_image_file import MessageContentImageFile\n","from openai.types.beta.threads.message_content_text import MessageContentText\n","from openai.types.beta.threads.messages import MessageFile\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{},"source":["### Create an Azure OpenAI client"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client = AzureOpenAI(api_key=api_key, api_version=api_version, azure_endpoint=api_endpoint)"]},{"cell_type":"markdown","metadata":{},"source":["### Create an Assistant and a Thread"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["assistant = client.beta.assistants.create(\n","    name=\"Math Tutor\",\n","    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n","    tools=[{\"type\": \"code_interpreter\"}],\n","    model=api_deployment_name,\n",")\n","\n","thread = client.beta.threads.create()"]},{"cell_type":"markdown","metadata":{},"source":["### Format and display the Assistant Messages for text and images"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_assistant_file(file_id:str):\n","    response_content = client.files.content(file_id)\n","    return response_content.read()\n","\n","def print_messages(messages: Iterable[MessageFile]) -> None:\n","    message_list = []\n","\n","    # Get all the messages till the last user message\n","    for message in messages:\n","        message_list.append(message)\n","        if message.role == \"user\":\n","            break\n","\n","    # Reverse the messages to show the last user message first\n","    message_list.reverse()\n","\n","    # Print the user or Assistant messages or images\n","    for message in message_list:\n","        for item in message.content:\n","            # Determine the content type\n","            if isinstance(item, MessageContentText):\n","                print(f\"{message.role}:\\n{item.text.value}\\n\")\n","                file_annotations = item.text.annotations\n","                if file_annotations:\n","                    for annotation in file_annotations:\n","                        file_id = annotation.file_path.file_id\n","                        content = read_assistant_file(file_id)\n","                        print(f\"Annotation Content:\\n{str(content)}\\n\")\n","            elif isinstance(item, MessageContentImageFile):\n","                # Retrieve image from file id                \n","                data_in_bytes = read_assistant_file(item.image_file.file_id)\n","                # Convert bytes to image\n","                readable_buffer = io.BytesIO(data_in_bytes)\n","                image = Image.open(readable_buffer)\n","                # Resize image to fit in terminal\n","                width, height = image.size\n","                image = image.resize((width // 2, height // 2), Image.LANCZOS)\n","                # Display image\n","                image.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Process the user messages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def process_prompt(prompt: str) -> None:\n","    client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=prompt)\n","    run = client.beta.threads.runs.create(\n","        thread_id=thread.id,\n","        assistant_id=assistant.id,\n","        instructions=\"Please address the user as Jane Doe. The user has a premium account. Be assertive, accurate, and polite. Ask if the user has further questions. \"\n","        + \"The current date and time is: \"\n","        + datetime.now().strftime(\"%x %X\")\n","        + \". \",\n","    )\n","    print(\"processing ...\")\n","    while True:\n","        run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n","        if run.status == \"completed\":\n","            # Handle completed\n","            messages = client.beta.threads.messages.list(thread_id=thread.id)\n","            print_messages(messages)\n","            break\n","        if run.status == \"failed\":\n","            messages = client.beta.threads.messages.list(thread_id=thread.id)\n","            answer = messages.data[0].content[0].text.value\n","            print(f\"Failed User:\\n{prompt}\\nAssistant:\\n{answer}\\n\")\n","            # Handle failed\n","            break\n","        if run.status == \"expired\":\n","            # Handle expired\n","            print(run)\n","            break\n","        if run.status == \"cancelled\":\n","            # Handle cancelled\n","            print(run)\n","            break\n","        if run.status == \"requires_action\":\n","            # Handle function calling and continue processing\n","            pass\n","        else:\n","            time.sleep(5)"]},{"cell_type":"markdown","metadata":{},"source":["### Have a conversation with the Assistant"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["process_prompt(\"What is the linear equation when two (x,y) points are (1,1) and (5,10)?\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["process_prompt(\"I need to solve the equation `3x + 11 = 14`. Can you help me?\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["process_prompt(\"\"\"x=r*cos(u)sin(v), y=r*sin(u)sin(v), r=2+sin(7*u+5*v) for 0<u<2π and 0<v<π.\n","Create a graph of the equation z=r*cos(v).\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["process_prompt(\"create a csv file with 10 customer names\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["if should_cleanup:\n","    client.beta.assistants.delete(assistant.id)\n","    client.beta.threads.delete(thread.id)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"polyglot_notebook":{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"name":"csharp"}]}}},"nbformat":4,"nbformat_minor":0}
