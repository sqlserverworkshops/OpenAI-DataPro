{"cells":[{"cell_type":"markdown","metadata":{},"source":["![](../graphics/microsoftlogo.png)\n","\n","# Workshop: Unlocking AI Potential for the Data Professional - Azure OpenAI\n","\n","#### <i>A Microsoft Course from Microsoft Engineering and the FastTrack Team</i>\n","\n","<p style=\"border-bottom: 1px solid lightgrey;\"></p>\n","\n","<img style=\"float: left; margin: 0px 15px 15px 0px;\" src=\"https://raw.githubusercontent.com/microsoft/sqlworkshops/master/graphics/textbubble.png\"> <h2>Course Notebook: Module 3</h2>\n","\n","Welcome to this Microsoft solutions workshop on [*Unlocking AI Potential for the Data Professional with Azure OpenAI*](https://github.com/sqlserverworkshops/OpenAI-DataPro/tree/main). In this Notebook, you'll apply the concepts you learned in this Module.\n","\n","This Notebook contains recipes for some common applications of machine learning. You'll need a working knowledge of [pandas](http://pandas.pydata.org/), [matplotlib](http://matplotlib.org/), [numpy](http://www.numpy.org/), and, of course, [scikit-learn](http://scikit-learn.org/stable/) to benefit from it."]},{"cell_type":"markdown","metadata":{},"source":["# 3.1 Create Azure OpenAI Environment\n","\n","## Azure \n","\n","This notebook contains the script to create the necessary Azure environment to run the provided samples. The notebook uses [PowerShell](https://learn.microsoft.com/powershell/scripting/install/installing-powershell?view=powershell-7.3) and [Azure CLI](https://learn.microsoft.com/cli/azure/install-azure-cli) to deploy all necessary Azure resources. Both tools are available on Windows, macOS and Linux environments.\n","\n","## Configuration\n","\n","This notebook performs two tasks:\n","\n","- Deployment of necessary Azure Services (Azure OpenAI, Azure Cognitive Search) to run samples\n","- Store all necessary service endpoints, service API keys, Azure OpenAI deployment names in a centralized file (../01_DemoEnvironment/conf/application.env). This file is used by all notebooks in this repo to connect and authenticate against the deployed Azure services.\n","\n","If you already have instances of Azure OpenAI and Azure Cognitive Search running you can rename the [configuration template](../conf/.env-sample) to `.env` and provide endpoint, API key and deployment names of a chat completion and an embedding model. We suggest to run the notebook to start a clean environment.\n","\n","### Visual Studio Code\n","\n","If you are running these steps below in Visual Studio Code make sure you switch your kernal to .NET Interactive so that it will run the PowerShell"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1:   Login to Azure; Get, Set subscription"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Check if you are already logged in\n","$loggedIn = az account show --query \"name\" -o tsv\n","\n","if ($null -ne $loggedIn) {\n","    Write-Host \"Already logged in as $loggedIn\"\n","} else {\n","    Write-Host \"Logging in...\"\n","    az login\n","}\n","# Retrieve default subscription id\n","$subscriptionId = (\n","    (\n","        az account list -o json `\n","            --query \"[?isDefault]\"\n","    ) | ConvertFrom-Json\n",").id\n","\n","# Set Subscription\n","az account set --subscription $subscriptionId\n","Write-Host \"Subscription set to $subscriptionId\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","If you're already logged in:\n","```\n","    Already logged in as xxxxx\n","    Subscription set to xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n","```\n","If you aren't logged in a browser window will pop-up which allows you to log in\n","```\n","    Logging in...\n","    Subscription set to xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2:   Define project unifier\n","\n","The project unifier is used to allow multiple deployments of services which have a need for a unique custom endpoint."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$random = Get-Random -Minimum 100 -Maximum 999\n","\n","Write-Host \"Unifier set to: $random\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Unifier set to: xxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3:   Create Resource Group\n","\n","In this sample all resources are deployed to `eastus`. Feel free to change to your preferred location."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$resourceGroup = \"OpenAI-DataPro-RG\"\n","$location = \"eastus\"\n","\n","az group create `\n","    --location $location `\n","    --resource-group $resourceGroup"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created resource group`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4:   Create Azure OpenAI instance\n","\n","An instance of Azure Cognitive Service with the kind `OpenAI` will be created. The `endpoint` and `API key` of the newly created instance are retrieved for later storage in the `application.env` file."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$csOpenAIName = \"aiservices$random\"\n","\n","az cognitiveservices account create `\n","    --name $csOpenAIName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --kind OpenAI `\n","    --sku S0 `\n","    --yes\n","\n","$csOpenAIEndpoint = ( `\n","    az cognitiveservices account show `\n","        --name $csOpenAIName `\n","        --resource-group $resourceGroup `\n","        --query properties.endpoint `\n","        --output tsv `\n",")\n","\n","$csOpenAIApiKey = (\n","    az cognitiveservices account keys list `\n","        --name $csOpenAIName `\n","        --resource-group $resourceGroup `\n","        --query key1 `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created Azure OpenAI instance`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5:   Deploy Azure OpenAI models\n","\n","Two LLM models are deployed to the newly created Azure Cognitive Service instance: \n","\n","- A chat completion model. In the sample we're deploying `gpt-35-turbo`. This can be replaced with other models providing a chat completion interface like `gpt-4`.\n","- A text embedding model. In the sample we're deploying `text-embedding-ada-002`. Any other text embedding model can be deployed as well."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Chat Completion Model GPT-3.5-turbo\n","$AOAI_GPT35_DEPLOYMENT = \"gpt-35-turbo\"\n","$modelName = \"gpt-35-turbo\"\n","$modelVersion = \"0301\"\n","$modelFormat = \"OpenAI\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT35_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Chat Completion Model GPT-4\n","$AOAI_GPT4_DEPLOYMENT = \"gpt-4\"\n","$modelName = \"gpt-4\"\n","$modelVersion = \"0613\"\n","$modelFormat = \"OpenAI\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT4_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Text Embedding Model\n","$AOAI_EMBEDDING_DEPLOYMENT = \"text-embedding-ada-002\"\n","$modelName = \"text-embedding-ada-002\"\n","$modelVersion = \"2\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_EMBEDDING_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# GPT-4 Vision Model - GPT-4 Turbo with Vision is the version of GPT-4 that accepts image inputs. It is available as the vision-preview model of gpt-4. The vision-preview model is available in only certain regions. For more information, see\n","# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#standard-deployment-model-availability\n","$AOAI_GPT4VISION_DEPLOYMENT = \"gpt-4-vision\"\n","$modelName = \"gpt-4\"\n","$modelVersion = \"vision-preview\"\n","$scaleType = \"Standard\"\n","\n","az cognitiveservices account deployment create `\n","   --resource-group $resourceGroup `\n","   --name $csOpenAIName `\n","   --deployment-name $AOAI_GPT4VISION_DEPLOYMENT `\n","   --model-name $modelName `\n","   --model-version $modelVersion `\n","   --model-format $modelFormat `\n","   --sku-name $scaleType `\n","   --sku-capacity 1"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly deployed models`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 6:   Create Azure Cognitive Search\n","\n","Azure Cognitive Search is deployed to use its [vector DB functionalities](https://learn.microsoft.com/en-us/azure/search/vector-search-overview). Just like with Azure OpenAI Cognitive Service, the `endpoint` and `API key` of the newly created instance are retrieved for later storage in the `application.env` file."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$csSearchName = \"aisearch$random\"\n","$csSearchSku = \"standard\"\n","\n","az search service create `\n","    --name $csSearchName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --sku $csSearchSku\n","\n","$csSearchEndpoint = \"https://$csSearchName.search.windows.net\"\n","\n","$csSearchApiKey = ( `\n","    az search admin-key show `\n","        --resource-group $resourceGroup `\n","        --service-name $csSearchName `\n","        --query primaryKey `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n"," `JSON string describing the newly created cognitive search resource`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 7:   Create Azure Storage account\n","\n","Azure Storage is deployed to store data that can be used to generate indexes in Azure Cognitive Search."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["$stgName = \"aistg$random\"\n","$stgSku = \"Standard_LRS\"\n","\n","az storage account create `\n","    --name $stgName `\n","    --resource-group $resourceGroup `\n","    --location $location `\n","    --sku $stgSku `\n","    --kind StorageV2 `\n","    --https-only true `\n","    --access-tier Hot\n","\n","$stgConnectionString = ( `\n","    az storage account show-connection-string `\n","        --name $stgName `\n","        --resource-group $resourceGroup `\n","        --query connectionString `\n","        --output tsv `\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Expected output: \n","\n","`JSON string describing the newly created storage account`"]},{"cell_type":"markdown","metadata":{},"source":["## Step 8: Set environment variables & create application.env file"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"pwsh"},"polyglot_notebook":{"kernelName":"pwsh"}},"outputs":[],"source":["# Set environment variables\n","\n","$ENV:AOAI_ENDPOINT = $csOpenAIEndpoint\n","$ENV:AOAI_APIKEY = $csOpenAIApiKey\n","\n","#Azure Open AI GPT 3.5\n","$ENV:AOAI_GPT35_DEPLOYMENT = $AOAI_GPT35_DEPLOYMENT\n","\n","#Azure Open AI Embedding - text-embedding-ada-002\n","$ENV:AOAI_EMBEDDING_DEPLOYMENT = $AOAI_EMBEDDING_DEPLOYMENT\n","\n","#Azure Open AI GPT 4\n","$ENV:AOAI_GPT4_DEPLOYMENT = $AOAI_GPT4_DEPLOYMENT\n","\n","#Azure Open AI GPT 4 Vision\n","$ENV:AOAI_VISION_ENDPOINT = $csOpenAIEndpoint\n","$ENV:AOAI_VISION_APIKEY = $csOpenAIApiKey\n","$ENV:AOAI_GPT4VISION_DEPLOYMENT = $AOAI_GPT4VISION_DEPLOYMENT\n","\n","# Azure Search\n","$ENV:SEARCH_ENDPOINT = \"https://$csSearchEndpoint/\"\n","$ENV:SEARCH_APIKEY = $csSearchApiKey\n","\n","$ENV:STORAGE_CONNECTIONSTRING = $stgConnectionString\n","$ENV:ASSET_FOLDER = \"../../../../assets\"\n","\n","Write-Host \"Environment variables set!\"\n","\n","$configurationFile = \"../.env\"\n","\n","function Set-ConfigurationFileVariable($configurationFile, $variableName, $variableValue) {\n","    if (Select-String -Path $configurationFile -Pattern $variableName) {\n","        (Get-Content $configurationFile) | Foreach-Object {\n","            $_ -replace \"$variableName = .*\", \"$variableName=$variableValue\"\n","        } | Set-Content $configurationFile\n","    } else {\n","        Add-Content -Path $configurationFile -value \"$variableName=$variableValue\"\n","    }\n","}\n","\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_ENDPOINT\" $csOpenAIEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_APIKEY\" $csOpenAIApiKey\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT35_DEPLOYMENT\" $AOAI_GPT35_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_EMBEDDING_DEPLOYMENT\" $AOAI_EMBEDDING_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT4_DEPLOYMENT\" $AOAI_GPT4_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_VISION_ENDPOINT\" $csOpenAIEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_VISION_APIKEY\" $csOpenAIApiKey\n","Set-ConfigurationFileVariable $configurationFile \"AOAI_GPT4VISION_DEPLOYMENT\" $AOAI_GPT4VISION_DEPLOYMENT\n","Set-ConfigurationFileVariable $configurationFile \"SEARCH_ENDPOINT\" $csSearchEndpoint\n","Set-ConfigurationFileVariable $configurationFile \"SEARCH_APIKEY\" $csSearchApiKey\n","Set-ConfigurationFileVariable $configurationFile \"STORAGE_CONNECTIONSTRING\" $stgConnectionString\n","Set-ConfigurationFileVariable $configurationFile \"ASSET_FOLDER\" \"../../../../assets\"\n","\n","\n","Write-Host \"Configuration file created at: $configurationFile\""]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Environment variables set!\n","Configuration file created at: xxxxxxxxxxxx\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 3.2 Basic Chat\n","\n","In this notebook, we'll explore basic prompt engineering techniques and recommendations that will help us elicit responses from Azure OpenAI Models\n","\n","### Visual Studio Code\n","\n","If you are running these steps below in Visual Studio Code make sure you switch your kernal to Python\n"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# if needed, install and/or upgrade to the latest version of the OpenAI Python library\n","%pip install openai\n","%pip install panel "]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["%pip show openai"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["import os\n","from openai import AzureOpenAI\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2023-07-01-preview\"\n",")\n","\n","chatgpt_model_name = os.getenv(\"AOAI_GPT4_DEPLOYMENT\")\n","print(chatgpt_model_name)"]},{"cell_type":"markdown","metadata":{},"source":["Chat models take a series of messages as input, and return a model-generated message as output. The main input is the messages parameter. Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message)."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["# A sample API call for chat completions looks as follows:\n","# Messages must be an array of message objects, where each object has a role (either \"system\", \"user\", or \"assistant\") and content (the content of the message).\n","# For more info: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference#chat-completions\n","import openai\n","try:\n","   \n","    response = client.chat.completions.create(\n","    model=chatgpt_model_name,\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n","        {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n","    ],\n","    temperature=0,\n","    max_tokens=800\n","    )\n","\n","    print(response.choices[0].message)\n","\n"," \n","except openai.APIError as e:\n","    # Handle API error here, e.g. retry or log\n","    print(f\"OpenAI API returned an API Error: {e}\")\n","\n","except openai.AuthenticationError as e:\n","    # Handle Authentication error here, e.g. invalid API key\n","    print(f\"OpenAI API returned an Authentication Error: {e}\")\n","\n","except openai.APIConnectionError as e:\n","    # Handle connection error here\n","    print(f\"Failed to connect to OpenAI API: {e}\")\n","\n","except openai.RateLimitError as e:\n","    # Handle rate limit error\n","    print(f\"OpenAI API request exceeded rate limit: {e}\")\n","\n","except openai.APITimeoutError as e:\n","    # Handle request timeout\n","    print(f\"Request timed out: {e}\")\n","    \n","except:\n","    # Handles all other exceptions\n","    print(\"An exception has occured.\")"]},{"cell_type":"markdown","metadata":{},"source":["## C# Example:  Setup Parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["#r \"nuget: DotNetEnv, 2.5.0\"\n","#r \"nuget: System.Text.Json, 7.0.3\"\n","#r \"nuget: Newtonsoft.Json, 13.0.1\"\n","using DotNetEnv;\n","\n","using System.Net;\n","using System.Net.Http;\n","using System.Text.Json.Nodes;\n","using System.Text.Json;\n","\n","static string _configurationFile = @\"../.env\";\n","Env.Load(_configurationFile);\n","\n","string apiBase = Environment.GetEnvironmentVariable(\"AOAI_ENDPOINT\"); \n","string apiKey = Environment.GetEnvironmentVariable(\"AOAI_APIKEY\"); \n","string deploymentName = Environment.GetEnvironmentVariable(\"AOAI_GPT4_DEPLOYMENT\"); \n","string apiVersion = \"2023-07-01-preview\";"]},{"cell_type":"markdown","metadata":{},"source":["Expected output\n","```\n","Installed Packages\n","    DotNetEnv, 2.5.0\n","    Newtonsoft.Json, 13.0.1\n","    System.Text.Json, 7.0.3\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["Console.WriteLine(apiBase);\n","Console.WriteLine(apiKey);\n","Console.WriteLine(deploymentName);\n"]},{"cell_type":"markdown","metadata":{},"source":["## Create completions for chat messages with GPT models\n","\n","The code cell is using an instance of `HttpClient` to call the REST API of the deployed Azure OpenAI instance."]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var requestPayload = new JsonObject\n","{\n","    { \"messages\", new JsonArray\n","        {\n","            new JsonObject\n","            {\n","                { \"role\", \"system\" },\n","                { \"content\", \"You are an AI assistance who You extract intention from provided text. You always answer with intention:\" }\n","                \n","            },\n","            new JsonObject\n","            {\n","                { \"role\", \"user\" },\n","                { \"content\", \"I'm not receiving calls on my Samsung Galaxy S22. Can you help?\" }\n","            }\n","        }\n","    },\n","    { \"max_tokens\", 200 },\n","    { \"temperature\", 0.7 },\n","    { \"frequency_penalty\", 0 },\n","    { \"presence_penalty\", 0 },\n","    { \"top_p\", 0.95 },\n","    { \"stop\", null }\n","};\n","\n","string payload = JsonSerializer.Serialize(requestPayload, new JsonSerializerOptions\n","{\n","    WriteIndented = true // Optional: to make the JSON string more readable\n","});\n","\n","        \n","string endpoint = $\"{apiBase}openai/deployments/{deploymentName}/chat/completions?api-version={apiVersion}\";\n","\n","using (HttpClient httpClient = new HttpClient())\n","{\n","    httpClient.BaseAddress = new Uri(endpoint);\n","    httpClient.DefaultRequestHeaders.Add(\"api-key\",apiKey);\n","    httpClient.DefaultRequestHeaders.Accept.Add(new System.Net.Http.Headers.MediaTypeWithQualityHeaderValue(\"application/json\"));\n","\n","    var stringContent = new StringContent(payload, Encoding.UTF8, \"application/json\");\n","\n","    var response = await httpClient.PostAsync(endpoint, stringContent);\n","\n","    if (response.IsSuccessStatusCode)\n","    {\n","        using (var responseStream = await response.Content.ReadAsStreamAsync())\n","        {\n","            // Parse the JSON response using JsonDocument\n","            using (var jsonDoc = await JsonDocument.ParseAsync(responseStream))\n","            {\n","                // Access the message content dynamically\n","                var root = jsonDoc.RootElement;\n","                var messageContent = root.GetProperty(\"choices\")[0].GetProperty(\"message\").GetProperty(\"content\").GetString();\n","\n","                // Output the message content\n","                Console.WriteLine(\"Output: \" + messageContent);\n","            }\n","        }\n","    }\n","    else\n","    {\n","        Console.WriteLine($\"Error: {response}\");\n","    }\n","}"]},{"cell_type":"markdown","metadata":{},"source":["Expected output:\n","\n","```\n","Output: Intention: Requesting technical assistance with phone call issue on Samsung Galaxy S22.\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# 3.3 Tokenization\n","\n","In this notebook, we'll explore basic concepts behind tokenization, how to use the Microsoft.ML.Tokenizers library to tokenize text and get information about token counts\n","\n","https://github.com/Azure-Samples/openai-dotnet-samples/blob/main/tokenization.ipynb"]},{"cell_type":"markdown","metadata":{},"source":["### Install Microsoft.ML.Tokenizers"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["#r \"nuget:Microsoft.ML.Tokenizers\""]},{"cell_type":"markdown","metadata":{},"source":["Installed Packages\n"," - Microsoft.ML.Tokenizers, 0.21.1"]},{"cell_type":"markdown","metadata":{},"source":["### Add using statements"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["using Microsoft.ML.Tokenizers;"]},{"cell_type":"markdown","metadata":{},"source":["### Download and define vocab resources\n","\n","Download the following files and place them in the root directory. These vocabulary files are what are used to encode the text into tokens.\n","\n","- [GPT Vocabulary Files](https://huggingface.co/gpt2/tree/main)\n","    - vocab.json\n","    - merges.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var vocabFilePath = @\"../assets/vocab.json\";\n","var mergeFilePath = @\"../assets/merges.txt\";"]},{"cell_type":"markdown","metadata":{},"source":["### Initialize Tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var tokenizer = new Tokenizer(new Bpe(vocabFilePath, mergeFilePath));"]},{"cell_type":"markdown","metadata":{},"source":["### Encode text into tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["var input = \"the brown fox jumped over the lazy dog!\";\n","var tokenizerEncodedResult = tokenizer.Encode(input);\n","tokenizerEncodedResult"]},{"cell_type":"markdown","metadata":{},"source":["### Get token count"]},{"cell_type":"code","execution_count":null,"metadata":{"dotnet_interactive":{"language":"csharp"},"polyglot_notebook":{"kernelName":"csharp"}},"outputs":[],"source":["tokenizerEncodedResult.Tokens.Count()"]},{"cell_type":"markdown","metadata":{},"source":["# 3.3 Prompts & Completions\n","\n","In this section, we'll explore small prompt engineering techniques and recommendations that will help us elicit responses from the models that are better suited to our needs."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%pip install openai\n","%pip install panel "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from openai import AzureOpenAI\n","\n","print(os.getenv(\"AOAI_ENDPOINT\"))\n","print(os.getenv(\"AOAI_APIKEY\"))\n","\n","client = AzureOpenAI(\n","  azure_endpoint = os.getenv(\"AOAI_ENDPOINT\"),\n","  api_key = os.getenv(\"AOAI_APIKEY\"),  \n","  api_version = \"2023-07-01-preview\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Formating the answer with Few Shot Samples.\n","\n","To obtain the model's response in a specific format, we have various options, but one of the most convenient is to use Few-Shot Samples. This involves presenting the model with pairs of user queries and example responses.\n","\n","Large models like GPT-3.5 respond well to the examples provided, adapting their response to the specified format.\n","\n","Depending on the number of examples given, this technique can be referred to as:\n","* Zero-Shot - which refers to providing no examples\n","* One-Shot.\n","* Few-Shots - The term few-shot refers to providing a few of examples to help the model learn what it needs to do\n","\n","With One Shot should be enough, and it is recommended to use a maximum of six shots. It's important to remember that this information is passed in each query and occupies space in the input prompt.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Functio to call the model.\n","def return_OAIResponse(user_message, context):\n","\n","#As we can see, we’re adding the user’s question at the end of the prompt with the user role, so the model understands that this is a user request and not an instruction on how it should work.\n","    newcontext = context.copy()\n","    newcontext.append({'role':'user', 'content':\"question: \" + user_message})\n","\n","    # print(newcontext)\n","\n","    response = client.chat.completions.create(\n","        model=\"gpt-35-turbo\", # model = \"deployment_name\".\n","        messages=newcontext,\n","        temperature=0,\n","        max_tokens=800\n","    )\n","\n","    # print(response)\n","    print(response.model_dump_json(indent=2))\n","\n","    return (response.choices[0].message.content)"]},{"cell_type":"markdown","metadata":{},"source":["In this zero-shots prompt we obtain a correct response, but without formatting, as the model incorporates the information he wants."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#zero-shot\n","context_user = [\n","    {'role':'system', 'content':'You are an expert in F1.'}\n","]\n","print(return_OAIResponse(\"Who won the F1 2010?\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#one-shot\n","context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in F1.\n","\n","     Who won the 2000 f1 championship?\n","     Driver: Michael Schumacher.\n","     Team: Ferrari.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2011?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["Smaller models, or more complicated formats, may require more than one shot. Here a sample with two shots."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Few shots\n","context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in F1.\n","\n","     Who won the 2010 f1 championship?\n","     Driver: Sebastian Bettel.\n","     Team: Red Bull Renault.\n","\n","     Who won the 2009 f1 championship?\n","     Driver: Jenson Button.\n","     Team: BrawnGP.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["We've been creating the prompt without using OpenAI's roles, and as we've seen, it worked correctly.\n","\n","However, the proper way to do this is by using these roles to construct the prompt, making the model's learning process even more effective.\n","\n","By not feeding it the entire prompt as if they were system commands, we enable the model to learn from a conversation, which is more realistic for it."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Recomended solution\n","context_user = [\n","    {'role':'system', 'content':'You are and expert in f1.\\n\\n'},\n","    {'role':'user', 'content':'Who won the 2010 f1 championship?'},\n","    {'role':'assistant', 'content':\"\"\"Driver: Sebastian Bettel. \\nTeam: Red Bull. \\nPoints: 256. \"\"\"},\n","    {'role':'user', 'content':'Who won the 2009 f1 championship?'},\n","    {'role':'assistant', 'content':\"\"\"Driver: Jenson Button. \\nTeam: BrawnGP. \\nPoints: 95. \"\"\"},\n","]\n","\n","print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["We could also address it by using a more conventional prompt, describing what we want and how we want the format.\n","\n","However, it's essential to understand that in this case, the model is following instructions, whereas in the case of use shots, it is learning in real-time during inference."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user = [\n","    {'role':'system', 'content':\"\"\"You are and expert in f1.\n","    You are going to answew the question of the user giving the name of the rider,\n","    the name of the team and the points of the champion, following the format:\n","    Drive:\n","    Team:\n","    Points: \"\"\"\n","    }\n","]\n","\n","print(return_OAIResponse(\"Who won the F1 2019?\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are classifying .\n","\n","     Who won the 2010 f1 championship?\n","     Driver: Sebastian Bettel.\n","     Team: Red Bull Renault.\n","\n","     Who won the 2009 f1 championship?\n","     Driver: Jenson Button.\n","     Team: BrawnGP.\"\"\"}\n","]\n","print(return_OAIResponse(\"Who won the F1 2006?\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["### Few Shots for classification."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user = [\n","    {'role':'system', 'content':\n","     \"\"\"You are an expert in reviewing product opinions and classifying them as positive or negative.\n","\n","     It fulfilled its function perfectly, I think the price is fair, I would buy it again.\n","     Setiment: Positive\n","\n","     It didn't work bad, but I wouldn't buy it again, maybe it's a bit expensive for what it does.\n","     Sentiment: Negative.\n","\n","     I wouldn't know what to say, my son uses it, but he doesn't love it.\n","     Sentiment: Neutral\n","     \"\"\"}\n","]\n","print(return_OAIResponse(\"I'm not going to return it, but I don't plan to buy it again.\", context_user))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["context_user=[\n","        {\"role\": \"system\", \"content\": \"You are an OrderBot in a fastfood restaurant.\"},\n","        {\"role\": \"user\", \"content\": \"I have only 10 dollars, what can I order?\"},\n","        {\"role\": \"assistant\", \"content\": \"We have the fast menu for 7 dollars.\"},\n","        {\"role\": \"user\", \"content\": \"Perfect! Give me one! \"}\n","]\n","print(return_OAIResponse(\"\", context_user))"]},{"cell_type":"markdown","metadata":{},"source":["## Content Generation\n","\n","In this section, we'll explore how to use LLMs to do content generation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mock_get_car() -> dict:\n","    return {\n","        \"make\": \"Ford\",\n","        \"model\": \"Explorer\",\n","        \"base\": \"XLT\",\n","        \"color\": \"red\",\n","        \"year\": 2019,\n","        \"condition\": \"good\",\n","        \"mileage\": 32000,\t\n","        \"price\": 25000\n","    }\n","\n","def get_car_description(car: dict) -> str:\n","    return f'{car[\"year\"]} {car[\"make\"]} {car[\"model\"]} {car[\"base\"]} {car[\"color\"]} with {car[\"mileage\"]} miles in {car[\"condition\"]} condition for ${car[\"price\"]}.'\n","\n","car = mock_get_car()\n","car_description = get_car_description(car)\n","\n","# Create a semantic kernel inline function\n","sales_desc_generation_template = \"Create a one paragraph sales description that includes the price for a {{input}}\"\n","template = common.render_template(sales_desc_generation_template, input=car_description)\n","\n","# Execute the SK function\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,template,max_tokens=500))"]},{"cell_type":"markdown","metadata":{},"source":["## Classification\n","\n","In this section, we'll explore how to use LLMs to do classification"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=\"2023-12-01-preview\",\n","        azure_endpoint=common.api_URI)\n","\n","print(common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["prompt_template = \"\"\"For the following list of animals:\n","\n","- Dog\n","- Cat\n","- Elephant\n","- Dolphin\n","- Shark\n","- Whale\n","- Snake\n","\n","Can you classify and list by animal type?\n","\"\"\"\n","\n","result = common.Call_OpenAI(client,common.gpt_api_deployment,prompt_template)\n","\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["## Recommendations\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def mock_get_restaurant_list(cityCode) -> list[str]:\n","    if (cityCode == \"MIA\"):\n","        return [\n","            \"Joe's Stone Crab\",\n","            \"Versailles\",\n","            \"Hillstone\",\n","            \"Casa Tua\",\t\n","            \"Cecconi's\",\n","            \"Yardbird Southern Table & Bar\",\n","        ]\n","    return []\n","\n","target_text=\"\"\n","for restaurant in mock_get_restaurant_list(\"MIA\"):\n","    target_text += f\"{restaurant}\\n\"\n","\n","print(target_text)\n","\n","recommendation_template = 'List two top restaurants:\\n{{input}}\\nOut in JSON format.'\n","print(recommendation_template)\n","rendered_template = common.render_template(recommendation_template, input=target_text)\n","print(rendered_template)\n","\n","print(common.Call_OpenAI(client,common.gpt_api_deployment,rendered_template,max_tokens=200))"]},{"cell_type":"markdown","metadata":{},"source":["## Translation with Semantic Kernal\n","\n","In this section, we'll explore how to use LLMs to do recommendations"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured model\n","client = common.get_openai_client(api_key=common.api_KEY,\n","        api_version=common.api_version,\n","        azure_endpoint=common.api_URI)\n","\n","print(common.api_KEY)\n","print(common.api_version)\n","print(common.api_URI)\n","# print(azure_endpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import common\n","\n","# Get a configured Semantic Kernel\n","# Note all other demos except this one use the OpenAI SDK\n","kernel = common.get_kernel()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"},"polyglot_notebook":{"kernelInfo":{"defaultKernelName":"csharp","items":[{"aliases":[],"name":"csharp"}]}}},"nbformat":4,"nbformat_minor":0}
